{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.3-Getting_the_most_out_of_your_models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcglarry/useful_keras/blob/master/7_3_Getting_the_most_out_of_your_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uBHic00A-j51",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 7.3 Getting the most out of your models \n",
        "## Chap 7 «Advanced Deep-learning best practices»\n",
        "## «Deep Learning with Python» book by François Chollet\n",
        "\n",
        "This notebook contains the code samples found in Chapter 7 of «Deep Learning with Python». Note that the original text features far more content, in particular further explanations and figures. \n",
        "\n",
        "修改與補充Claude COULOMBE的github :https://github.com/ClaudeCoulombe/deep-learning-with-python-notebooks (by Claude COULOMBE - PhD candidate - TÉLUQ / UQAM - Montréal.)"
      ]
    },
    {
      "metadata": {
        "id": "3hHC6NWB-j55",
        "colab_type": "code",
        "outputId": "47e0764d-c55d-476c-ea07-2005a3e13eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# sudo pip3 install --ignore-installed --upgrade tensorflow\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as KTF\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.Session(config=config)\n",
        "KTF.set_session(session)\n",
        "import keras\n",
        "#import tensorflow as tf\n",
        "print(keras.__version__)\n",
        "print(tf.__version__)\n",
        "# To ignore keep_dims warning\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.4\n",
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ozweuJUQRRWI",
        "colab_type": "code",
        "outputId": "1c41bff5-1e8c-47e8-d3c4-a8cf34643d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3492
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install graphviz \n",
        "!apt-get install graphviz \n",
        "# Install pydot to visualize the network structure\n",
        "!pip install pydot\n",
        "!pip install pydot-ng\n",
        "\n",
        "#After fininishing the installation, you have to restart the colab runtime!!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting graphviz\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
            "Installing collected packages: graphviz\n",
            "Successfully installed graphviz-0.10.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fontconfig libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libgd3\n",
            "  libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libjbig0 liblab-gamut1 libltdl7\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpathplan4\n",
            "  libpixman-1-0 libthai-data libthai0 libtiff5 libwebp6 libxaw7 libxcb-render0\n",
            "  libxcb-shm0 libxmu6 libxpm4 libxt6\n",
            "Suggested packages:\n",
            "  gsfonts graphviz-doc libgd-tools\n",
            "The following NEW packages will be installed:\n",
            "  fontconfig graphviz libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libgd3\n",
            "  libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libjbig0 liblab-gamut1 libltdl7\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpathplan4\n",
            "  libpixman-1-0 libthai-data libthai0 libtiff5 libwebp6 libxaw7 libxcb-render0\n",
            "  libxcb-shm0 libxmu6 libxpm4 libxt6\n",
            "0 upgraded, 30 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 4,154 kB of archives.\n",
            "After this operation, 16.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig amd64 2.12.6-0ubuntu2 [169 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libann0 amd64 1.1.2+doc-6 [24.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcdt5 amd64 2.40.1-2 [19.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcgraph6 amd64 2.40.1-2 [40.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig0 amd64 2.1-3.1build1 [26.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtiff5 amd64 4.0.9-5 [152 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwebp6 amd64 0.6.1-2 [185 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxpm4 amd64 1:3.5.12-1 [34.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgd3 amd64 2.2.5-4ubuntu0.2 [119 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-0.7-5 amd64 0.7.6+darcs121130-4 [150 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-0 amd64 0.34.0-2 [229 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-render0 amd64 1.13-1 [14.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-shm0 amd64 1.13-1 [5,572 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcairo2 amd64 1.15.10-2 [580 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libltdl7 amd64 2.4.6-2 [38.8 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai-data all 0.1.27-2 [133 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdatrie1 amd64 0.2.10-7 [17.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai0 amd64 0.1.27-2 [18.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango-1.0-0 amd64 1.40.14-1ubuntu0.1 [153 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoft2-1.0-0 amd64 1.40.14-1ubuntu0.1 [33.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangocairo-1.0-0 amd64 1.40.14-1ubuntu0.1 [20.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpathplan4 amd64 2.40.1-2 [22.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6 amd64 2.40.1-2 [601 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvpr2 amd64 2.40.1-2 [169 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblab-gamut1 amd64 2.40.1-2 [178 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxt6 amd64 1:1.1.5-1 [160 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu6 amd64 2:1.1.2-2 [46.0 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxaw7 amd64 2:1.0.13-1 [173 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 graphviz amd64 2.40.1-2 [601 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-bin amd64 0.7.6+darcs121130-4 [41.3 kB]\n",
            "Fetched 4,154 kB in 3s (1,234 kB/s)\n",
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... 26397 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
            "Selecting previously unselected package libann0.\n",
            "Preparing to unpack .../01-libann0_1.1.2+doc-6_amd64.deb ...\n",
            "Unpacking libann0 (1.1.2+doc-6) ...\n",
            "Selecting previously unselected package libcdt5.\n",
            "Preparing to unpack .../02-libcdt5_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcdt5 (2.40.1-2) ...\n",
            "Selecting previously unselected package libcgraph6.\n",
            "Preparing to unpack .../03-libcgraph6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcgraph6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../04-libjbig0_2.1-3.1build1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../05-libtiff5_4.0.9-5_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.9-5) ...\n",
            "Selecting previously unselected package libwebp6:amd64.\n",
            "Preparing to unpack .../06-libwebp6_0.6.1-2_amd64.deb ...\n",
            "Unpacking libwebp6:amd64 (0.6.1-2) ...\n",
            "Selecting previously unselected package libxpm4:amd64.\n",
            "Preparing to unpack .../07-libxpm4_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libgd3:amd64.\n",
            "Preparing to unpack .../08-libgd3_2.2.5-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Selecting previously unselected package libgts-0.7-5:amd64.\n",
            "Preparing to unpack .../09-libgts-0.7-5_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../10-libpixman-1-0_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../11-libxcb-render0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../12-libxcb-shm0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../13-libcairo2_1.15.10-2_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.15.10-2) ...\n",
            "Selecting previously unselected package libltdl7:amd64.\n",
            "Preparing to unpack .../14-libltdl7_2.4.6-2_amd64.deb ...\n",
            "Unpacking libltdl7:amd64 (2.4.6-2) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../15-libthai-data_0.1.27-2_all.deb ...\n",
            "Unpacking libthai-data (0.1.27-2) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../16-libdatrie1_0.2.10-7_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../17-libthai0_0.1.27-2_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../18-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../19-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../20-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpathplan4.\n",
            "Preparing to unpack .../21-libpathplan4_2.40.1-2_amd64.deb ...\n",
            "Unpacking libpathplan4 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvc6.\n",
            "Preparing to unpack .../22-libgvc6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvc6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvpr2.\n",
            "Preparing to unpack .../23-libgvpr2_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvpr2 (2.40.1-2) ...\n",
            "Selecting previously unselected package liblab-gamut1.\n",
            "Preparing to unpack .../24-liblab-gamut1_2.40.1-2_amd64.deb ...\n",
            "Unpacking liblab-gamut1 (2.40.1-2) ...\n",
            "Selecting previously unselected package libxt6:amd64.\n",
            "Preparing to unpack .../25-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
            "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
            "Selecting previously unselected package libxmu6:amd64.\n",
            "Preparing to unpack .../26-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxaw7:amd64.\n",
            "Preparing to unpack .../27-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package graphviz.\n",
            "Preparing to unpack .../28-graphviz_2.40.1-2_amd64.deb ...\n",
            "Unpacking graphviz (2.40.1-2) ...\n",
            "Selecting previously unselected package libgts-bin.\n",
            "Preparing to unpack .../29-libgts-bin_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Setting up libpathplan4 (2.40.1-2) ...\n",
            "Setting up liblab-gamut1 (2.40.1-2) ...\n",
            "Setting up libxcb-render0:amd64 (1.13-1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
            "Setting up libtiff5:amd64 (4.0.9-5) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libltdl7:amd64 (2.4.6-2) ...\n",
            "Setting up libann0 (1.1.2+doc-6) ...\n",
            "Setting up libxcb-shm0:amd64 (1.13-1) ...\n",
            "Setting up libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libthai-data (0.1.27-2) ...\n",
            "Setting up libcdt5 (2.40.1-2) ...\n",
            "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up libcgraph6 (2.40.1-2) ...\n",
            "Setting up libwebp6:amd64 (0.6.1-2) ...\n",
            "Setting up libcairo2:amd64 (1.15.10-2) ...\n",
            "Setting up libgvpr2 (2.40.1-2) ...\n",
            "Setting up libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Setting up libthai0:amd64 (0.1.27-2) ...\n",
            "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libgvc6 (2.40.1-2) ...\n",
            "Setting up graphviz (2.40.1-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Collecting pydot\n",
            "  Downloading https://files.pythonhosted.org/packages/53/11/9db5c788f5ad05438b7c2a07fd7edd9820b7f3d95bb0690a16f7bf426204/pydot-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.3.0)\n",
            "Installing collected packages: pydot\n",
            "Successfully installed pydot-1.4.0\n",
            "Collecting pydot-ng\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/5b/9a08333f2d70d404ffe42cea4f50159c4ad94feaa4d7585551c05cacef46/pydot_ng-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from pydot-ng) (2.3.0)\n",
            "Installing collected packages: pydot-ng\n",
            "Successfully installed pydot-ng-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "RosbCio0-j6I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7.3. Getting the most out of your models\n",
        "\n",
        "In this section, we’ll go beyond “works okay” to “works great and wins machine-learning competitions” by offering you a quick guide to a set of must-know techniques for building state-of-the-art deep-learning models. "
      ]
    },
    {
      "metadata": {
        "id": "cHmdlAFn-j6K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.3.1. Advanced architecture patterns \n",
        "\n",
        "We covered one important design pattern in detail in the previous section: residual connections. There are two more design patterns you should know about: normalization and depthwise separable convolution. "
      ]
    },
    {
      "metadata": {
        "id": "0t_2j_Lu-j6N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Normalization\n",
        "\n",
        "<i>Normalization</i> is a broad category of methods that seek to make different samples seen by a machine-learning model more similar to each other, which helps the model learn and generalize well to new data. The most common form of data normalization is one you’ve seen several times in this book already: centering the data on 0 by subtracting the mean from the data, and giving the data a unit standard deviation by dividing the data by its standard deviation based on the assumption that the data follows a normal (or Gaussian) distribution:\n",
        "\n",
        "```Python\n",
        "    normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)\n",
        "```\n",
        "\n",
        "#### Batch normalization \n",
        "\n",
        "Data normalization should be a concern after every transformation operated by the network: even if the data entering a Dense or Conv2D network has a 0 mean and unit variance, there’s no reason to expect a priori that this will be the case for the data coming out. \n",
        "\n",
        "<i>Batch normalization</i> is a type of layer (`BatchNormalization` in Keras) introduced in 2015 by Ioffe and Szegedy that can adaptively normalize data even as the mean and variance change over time during training. It works by internally maintaining an exponential moving average of the batch-wise mean and variance of the data seen during training. The main effect of batch normalization is that it helps with gradient propagation and allows deeper networks. For instance, BatchNormalization is used liberally in many of the advanced convnet architectures that come packaged with Keras, such as ResNet50, Inception V3, and Xception.  \n",
        "\n",
        "The `BatchNormalization` layer is typically used after a convolutional or densely connected layer:\n",
        "\n",
        "```Python\n",
        "    conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
        "    # Batch normalization used after a Conv layer\n",
        "    conv_model.add(layers.BatchNormalization())\n",
        "\n",
        "    dense_model.add(layers.Dense(32, activation='relu'))\n",
        "    # Batch normalization used after a Dense layer\n",
        "    dense_model.add(layers.BatchNormalization())\n",
        "```\n",
        "The `BatchNormalization` layer takes an axis argument, which specifies the feature axis that should be normalized. This argument defaults to -1, the last axis in the input tensor. This is the correct value when using Dense layers, Conv1D layers, RNN layers, and Conv2D layers with data_format set to \"channels_last\". But in the niche use case of Conv2D layers with data_format set to \"channels_first\", the features axis is axis 1; the axis argument in BatchNormalization should accordingly be set to 1."
      ]
    },
    {
      "metadata": {
        "id": "8brFj4yO-j6Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Batch renormalization \n",
        "A recent improvement over regular batch normalization is batch renormalization, introduced by Ioffe in 2017. It offers clears benefits over batch normalization, at no apparent cost. At the time of writing, it’s too early to tell whether it will supplant batch normalization. Even more recently, Klambauer et al. introduced self-normalizing neural networks,which manage to keep data normalized after going through any Dense layer by using a specific activation function (`selu`) and a specific initializer (`lecun_normal`). This scheme, although highly interesting, is limited to densely connected networks for now, and its usefulness hasn’t yet been broadly replicated."
      ]
    },
    {
      "metadata": {
        "id": "rYNwchcC-j6U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Depthwise separable convolution \n",
        "<i>Depthwise separable convolution layer</i> can make a model lighter (fewer trainable weight parameters) and faster (fewer floating-point operations) and cause it to perform a few percentage points better on its task. The For example, SeparableConv2D layer performs a spatial convolution on each channel of its input, independently, before mixing output channels via a pointwise convolution (a 1 × 1 convolution). This is equivalent to separating the learning of spatial features and the learning of channel-wise features. It requires significantly fewer parameters and involves fewer computations, thus resulting in smaller, speedier models. And because it’s a more representationally efficient way to perform convolution, it tends to learn better representations using less data, resulting in better-performing models. \n",
        "\n",
        "These advantages become especially important when you’re training small models from scratch on limited data. For instance, here’s how you can build a lightweight, depthwise separable convnet for an image-classification task (softmax categorical classification) on a small dataset:\n",
        "\n",
        "When it comes to larger-scale models, depthwise separable convolutions are the basis of the Xception architecture, a high-performing convnet that comes packaged with Keras. "
      ]
    },
    {
      "metadata": {
        "id": "-Wi9V_Fr-j6V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training a Depthwise separable convolution\n",
        "#####  on the CIFAR10 dataset\n",
        "![alt text](https://storage.googleapis.com/kaggle-competitions/kaggle/3649/logos/front_page.png)\n",
        "\n",
        "The original code above requires an imges dataset in the format 64 height x 64 width x 3 channels. Furthermore, in order to work, depthwise separable convolution needs multichannel data, so MNIST dataset is not appropriate (28x28x1) since that has only one channel. Fortunately, KERAS has the CIFAR10 dataset which is in the format (32x32x3), so 3 channels. \n",
        "\n",
        "Therefore, we will adapt a code example from the KERAS GitHub repo: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
      ]
    },
    {
      "metadata": {
        "id": "kmFFkgCG-j6Z",
        "colab_type": "code",
        "outputId": "3ce788e9-6e3a-4986-c13c-eba23af27cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
        "\n",
        "'''Trains a Depthwise separable convolution on the CIFAR10 dataset.\n",
        "'''\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "# input image dimensions\n",
        "img_height = 32\n",
        "img_width = 32\n",
        "channels = 3\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print (K.image_data_format())\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model_a = Sequential()\n",
        "model_a.add(layers.SeparableConv2D(32, 3,\n",
        "                                 activation='relu',\n",
        "                                 input_shape=(img_height, img_width, channels,))) \n",
        "model_a.add(layers.BatchNormalization())\n",
        "model_a.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
        "model_a.add(layers.BatchNormalization())\n",
        "model_a.add(layers.MaxPooling2D(2))\n",
        "model_a.add(Dropout(0.25))\n",
        "model_a.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
        "model_a.add(layers.BatchNormalization())\n",
        "model_a.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
        "model_a.add(layers.BatchNormalization())\n",
        "model_a.add(layers.MaxPooling2D(2)) \n",
        "model_a.add(Dropout(0.25))\n",
        "model_a.add(layers.SeparableConv2D(64, 3, activation='relu')) \n",
        "model_a.add(layers.BatchNormalization())\n",
        "model_a.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
        "model_a.add(layers.BatchNormalization())\n",
        "model_a.add(layers.GlobalAveragePooling2D())\n",
        "model_a.add(layers.Dense(32, activation='relu'))\n",
        "model_a.add(layers.BatchNormalization())\n",
        "model_a.add(Dropout(0.5))\n",
        "model_a.add(layers.Dense(num_classes, activation='softmax')) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "channels_last\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TWh0ok2t-j6h",
        "colab_type": "code",
        "outputId": "02bf226b-4ab1-4434-9617-6ee382ddecfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3435
        }
      },
      "cell_type": "code",
      "source": [
        "model_a.summary()\n",
        "from keras.utils import plot_model \n",
        "plot_model(model_a, to_file='model.png')\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model_a,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "separable_conv2d_1 (Separabl (None, 30, 30, 32)        155       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_2 (Separabl (None, 28, 28, 64)        2400      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_3 (Separabl (None, 12, 12, 64)        4736      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_4 (Separabl (None, 10, 10, 128)       8896      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 10, 10, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_5 (Separabl (None, 3, 3, 64)          9408      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 3, 3, 64)          256       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_6 (Separabl (None, 1, 1, 128)         8896      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 1, 1, 128)         512       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 40,997\n",
            "Trainable params: 39,973\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"1788pt\" viewBox=\"0.00 0.00 527.00 1788.00\" width=\"527pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1784)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-1784 523,-1784 523,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140068496967664 -->\n<g class=\"node\" id=\"node1\">\n<title>140068496967664</title>\n<polygon fill=\"none\" points=\"44,-1660.5 44,-1706.5 475,-1706.5 475,-1660.5 44,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1679.8\">separable_conv2d_1: SeparableConv2D</text>\n<polyline fill=\"none\" points=\"292,-1660.5 292,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"292,-1683.5 350,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"350,-1660.5 350,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1691.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"350,-1683.5 475,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1668.3\">(None, 30, 30, 32)</text>\n</g>\n<!-- 140068496967440 -->\n<g class=\"node\" id=\"node2\">\n<title>140068496967440</title>\n<polygon fill=\"none\" points=\"32.5,-1577.5 32.5,-1623.5 486.5,-1623.5 486.5,-1577.5 32.5,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1596.8\">batch_normalization_1: BatchNormalization</text>\n<polyline fill=\"none\" points=\"303.5,-1577.5 303.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"303.5,-1600.5 361.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"361.5,-1577.5 361.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-1608.3\">(None, 30, 30, 32)</text>\n<polyline fill=\"none\" points=\"361.5,-1600.5 486.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-1585.3\">(None, 30, 30, 32)</text>\n</g>\n<!-- 140068496967664&#45;&gt;140068496967440 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140068496967664-&gt;140068496967440</title>\n<path d=\"M259.5,-1660.3799C259.5,-1652.1745 259.5,-1642.7679 259.5,-1633.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-1633.784 259.5,-1623.784 256.0001,-1633.784 263.0001,-1633.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068496968168 -->\n<g class=\"node\" id=\"node3\">\n<title>140068496968168</title>\n<polygon fill=\"none\" points=\"44,-1494.5 44,-1540.5 475,-1540.5 475,-1494.5 44,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1513.8\">separable_conv2d_2: SeparableConv2D</text>\n<polyline fill=\"none\" points=\"292,-1494.5 292,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"292,-1517.5 350,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"350,-1494.5 350,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1525.3\">(None, 30, 30, 32)</text>\n<polyline fill=\"none\" points=\"350,-1517.5 475,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1502.3\">(None, 28, 28, 64)</text>\n</g>\n<!-- 140068496967440&#45;&gt;140068496968168 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140068496967440-&gt;140068496968168</title>\n<path d=\"M259.5,-1577.3799C259.5,-1569.1745 259.5,-1559.7679 259.5,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-1550.784 259.5,-1540.784 256.0001,-1550.784 263.0001,-1550.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068496968392 -->\n<g class=\"node\" id=\"node4\">\n<title>140068496968392</title>\n<polygon fill=\"none\" points=\"32.5,-1411.5 32.5,-1457.5 486.5,-1457.5 486.5,-1411.5 32.5,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1430.8\">batch_normalization_2: BatchNormalization</text>\n<polyline fill=\"none\" points=\"303.5,-1411.5 303.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"303.5,-1434.5 361.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"361.5,-1411.5 361.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-1442.3\">(None, 28, 28, 64)</text>\n<polyline fill=\"none\" points=\"361.5,-1434.5 486.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-1419.3\">(None, 28, 28, 64)</text>\n</g>\n<!-- 140068496968168&#45;&gt;140068496968392 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140068496968168-&gt;140068496968392</title>\n<path d=\"M259.5,-1494.3799C259.5,-1486.1745 259.5,-1476.7679 259.5,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-1467.784 259.5,-1457.784 256.0001,-1467.784 263.0001,-1467.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068387083824 -->\n<g class=\"node\" id=\"node5\">\n<title>140068387083824</title>\n<polygon fill=\"none\" points=\"57.5,-1328.5 57.5,-1374.5 461.5,-1374.5 461.5,-1328.5 57.5,-1328.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1347.8\">max_pooling2d_1: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"278.5,-1328.5 278.5,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.5\" y=\"-1359.3\">input:</text>\n<polyline fill=\"none\" points=\"278.5,-1351.5 336.5,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.5\" y=\"-1336.3\">output:</text>\n<polyline fill=\"none\" points=\"336.5,-1328.5 336.5,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"399\" y=\"-1359.3\">(None, 28, 28, 64)</text>\n<polyline fill=\"none\" points=\"336.5,-1351.5 461.5,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"399\" y=\"-1336.3\">(None, 14, 14, 64)</text>\n</g>\n<!-- 140068496968392&#45;&gt;140068387083824 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140068496968392-&gt;140068387083824</title>\n<path d=\"M259.5,-1411.3799C259.5,-1403.1745 259.5,-1393.7679 259.5,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-1384.784 259.5,-1374.784 256.0001,-1384.784 263.0001,-1384.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068386629728 -->\n<g class=\"node\" id=\"node6\">\n<title>140068386629728</title>\n<polygon fill=\"none\" points=\"101,-1245.5 101,-1291.5 418,-1291.5 418,-1245.5 101,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1264.8\">dropout_1: Dropout</text>\n<polyline fill=\"none\" points=\"235,-1245.5 235,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"235,-1268.5 293,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"293,-1245.5 293,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-1276.3\">(None, 14, 14, 64)</text>\n<polyline fill=\"none\" points=\"293,-1268.5 418,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-1253.3\">(None, 14, 14, 64)</text>\n</g>\n<!-- 140068387083824&#45;&gt;140068386629728 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140068387083824-&gt;140068386629728</title>\n<path d=\"M259.5,-1328.3799C259.5,-1320.1745 259.5,-1310.7679 259.5,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-1301.784 259.5,-1291.784 256.0001,-1301.784 263.0001,-1301.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068386629448 -->\n<g class=\"node\" id=\"node7\">\n<title>140068386629448</title>\n<polygon fill=\"none\" points=\"44,-1162.5 44,-1208.5 475,-1208.5 475,-1162.5 44,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1181.8\">separable_conv2d_3: SeparableConv2D</text>\n<polyline fill=\"none\" points=\"292,-1162.5 292,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"292,-1185.5 350,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"350,-1162.5 350,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1193.3\">(None, 14, 14, 64)</text>\n<polyline fill=\"none\" points=\"350,-1185.5 475,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1170.3\">(None, 12, 12, 64)</text>\n</g>\n<!-- 140068386629728&#45;&gt;140068386629448 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140068386629728-&gt;140068386629448</title>\n<path d=\"M259.5,-1245.3799C259.5,-1237.1745 259.5,-1227.7679 259.5,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-1218.784 259.5,-1208.784 256.0001,-1218.784 263.0001,-1218.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068386870384 -->\n<g class=\"node\" id=\"node8\">\n<title>140068386870384</title>\n<polygon fill=\"none\" points=\"32.5,-1079.5 32.5,-1125.5 486.5,-1125.5 486.5,-1079.5 32.5,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1098.8\">batch_normalization_3: BatchNormalization</text>\n<polyline fill=\"none\" points=\"303.5,-1079.5 303.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"303.5,-1102.5 361.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"361.5,-1079.5 361.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-1110.3\">(None, 12, 12, 64)</text>\n<polyline fill=\"none\" points=\"361.5,-1102.5 486.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-1087.3\">(None, 12, 12, 64)</text>\n</g>\n<!-- 140068386629448&#45;&gt;140068386870384 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140068386629448-&gt;140068386870384</title>\n<path d=\"M259.5,-1162.3799C259.5,-1154.1745 259.5,-1144.7679 259.5,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-1135.784 259.5,-1125.784 256.0001,-1135.784 263.0001,-1135.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068385907768 -->\n<g class=\"node\" id=\"node9\">\n<title>140068385907768</title>\n<polygon fill=\"none\" points=\"40.5,-996.5 40.5,-1042.5 478.5,-1042.5 478.5,-996.5 40.5,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-1015.8\">separable_conv2d_4: SeparableConv2D</text>\n<polyline fill=\"none\" points=\"288.5,-996.5 288.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"288.5,-1019.5 346.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"346.5,-996.5 346.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1027.3\">(None, 12, 12, 64)</text>\n<polyline fill=\"none\" points=\"346.5,-1019.5 478.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1004.3\">(None, 10, 10, 128)</text>\n</g>\n<!-- 140068386870384&#45;&gt;140068385907768 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140068386870384-&gt;140068385907768</title>\n<path d=\"M259.5,-1079.3799C259.5,-1071.1745 259.5,-1061.7679 259.5,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-1052.784 259.5,-1042.784 256.0001,-1052.784 263.0001,-1052.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068385159768 -->\n<g class=\"node\" id=\"node10\">\n<title>140068385159768</title>\n<polygon fill=\"none\" points=\"29,-913.5 29,-959.5 490,-959.5 490,-913.5 29,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-932.8\">batch_normalization_4: BatchNormalization</text>\n<polyline fill=\"none\" points=\"300,-913.5 300,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"300,-936.5 358,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"358,-913.5 358,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-944.3\">(None, 10, 10, 128)</text>\n<polyline fill=\"none\" points=\"358,-936.5 490,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-921.3\">(None, 10, 10, 128)</text>\n</g>\n<!-- 140068385907768&#45;&gt;140068385159768 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140068385907768-&gt;140068385159768</title>\n<path d=\"M259.5,-996.3799C259.5,-988.1745 259.5,-978.7679 259.5,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-969.784 259.5,-959.784 256.0001,-969.784 263.0001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068385118024 -->\n<g class=\"node\" id=\"node11\">\n<title>140068385118024</title>\n<polygon fill=\"none\" points=\"54,-830.5 54,-876.5 465,-876.5 465,-830.5 54,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-849.8\">max_pooling2d_2: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"275,-830.5 275,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"275,-853.5 333,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"333,-830.5 333,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"399\" y=\"-861.3\">(None, 10, 10, 128)</text>\n<polyline fill=\"none\" points=\"333,-853.5 465,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"399\" y=\"-838.3\">(None, 5, 5, 128)</text>\n</g>\n<!-- 140068385159768&#45;&gt;140068385118024 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140068385159768-&gt;140068385118024</title>\n<path d=\"M259.5,-913.3799C259.5,-905.1745 259.5,-895.7679 259.5,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-886.784 259.5,-876.784 256.0001,-886.784 263.0001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068384160344 -->\n<g class=\"node\" id=\"node12\">\n<title>140068384160344</title>\n<polygon fill=\"none\" points=\"105,-747.5 105,-793.5 414,-793.5 414,-747.5 105,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-766.8\">dropout_2: Dropout</text>\n<polyline fill=\"none\" points=\"239,-747.5 239,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"239,-770.5 297,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"297,-747.5 297,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-778.3\">(None, 5, 5, 128)</text>\n<polyline fill=\"none\" points=\"297,-770.5 414,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-755.3\">(None, 5, 5, 128)</text>\n</g>\n<!-- 140068385118024&#45;&gt;140068384160344 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140068385118024-&gt;140068384160344</title>\n<path d=\"M259.5,-830.3799C259.5,-822.1745 259.5,-812.7679 259.5,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-803.784 259.5,-793.784 256.0001,-803.784 263.0001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068384160064 -->\n<g class=\"node\" id=\"node13\">\n<title>140068384160064</title>\n<polygon fill=\"none\" points=\"48,-664.5 48,-710.5 471,-710.5 471,-664.5 48,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-683.8\">separable_conv2d_5: SeparableConv2D</text>\n<polyline fill=\"none\" points=\"296,-664.5 296,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"325\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"296,-687.5 354,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"325\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"354,-664.5 354,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-695.3\">(None, 5, 5, 128)</text>\n<polyline fill=\"none\" points=\"354,-687.5 471,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-672.3\">(None, 3, 3, 64)</text>\n</g>\n<!-- 140068384160344&#45;&gt;140068384160064 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140068384160344-&gt;140068384160064</title>\n<path d=\"M259.5,-747.3799C259.5,-739.1745 259.5,-729.7679 259.5,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-720.784 259.5,-710.784 256.0001,-720.784 263.0001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068384394544 -->\n<g class=\"node\" id=\"node14\">\n<title>140068384394544</title>\n<polygon fill=\"none\" points=\"40,-581.5 40,-627.5 479,-627.5 479,-581.5 40,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.5\" y=\"-600.8\">batch_normalization_5: BatchNormalization</text>\n<polyline fill=\"none\" points=\"311,-581.5 311,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"340\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"311,-604.5 369,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"340\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"369,-581.5 369,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-612.3\">(None, 3, 3, 64)</text>\n<polyline fill=\"none\" points=\"369,-604.5 479,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-589.3\">(None, 3, 3, 64)</text>\n</g>\n<!-- 140068384160064&#45;&gt;140068384394544 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140068384160064-&gt;140068384394544</title>\n<path d=\"M259.5,-664.3799C259.5,-656.1745 259.5,-646.7679 259.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-637.784 259.5,-627.784 256.0001,-637.784 263.0001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068383437992 -->\n<g class=\"node\" id=\"node15\">\n<title>140068383437992</title>\n<polygon fill=\"none\" points=\"48,-498.5 48,-544.5 471,-544.5 471,-498.5 48,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-517.8\">separable_conv2d_6: SeparableConv2D</text>\n<polyline fill=\"none\" points=\"296,-498.5 296,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"325\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"296,-521.5 354,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"325\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"354,-498.5 354,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-529.3\">(None, 3, 3, 64)</text>\n<polyline fill=\"none\" points=\"354,-521.5 471,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-506.3\">(None, 1, 1, 128)</text>\n</g>\n<!-- 140068384394544&#45;&gt;140068383437992 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140068384394544-&gt;140068383437992</title>\n<path d=\"M259.5,-581.3799C259.5,-573.1745 259.5,-563.7679 259.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-554.784 259.5,-544.784 256.0001,-554.784 263.0001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068383036192 -->\n<g class=\"node\" id=\"node16\">\n<title>140068383036192</title>\n<polygon fill=\"none\" points=\"36.5,-415.5 36.5,-461.5 482.5,-461.5 482.5,-415.5 36.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-434.8\">batch_normalization_6: BatchNormalization</text>\n<polyline fill=\"none\" points=\"307.5,-415.5 307.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"307.5,-438.5 365.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"365.5,-415.5 365.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-446.3\">(None, 1, 1, 128)</text>\n<polyline fill=\"none\" points=\"365.5,-438.5 482.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-423.3\">(None, 1, 1, 128)</text>\n</g>\n<!-- 140068383437992&#45;&gt;140068383036192 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140068383437992-&gt;140068383036192</title>\n<path d=\"M259.5,-498.3799C259.5,-490.1745 259.5,-480.7679 259.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-471.784 259.5,-461.784 256.0001,-471.784 263.0001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068382442776 -->\n<g class=\"node\" id=\"node17\">\n<title>140068382442776</title>\n<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 519,-378.5 519,-332.5 0,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-351.8\">global_average_pooling2d_1: GlobalAveragePooling2D</text>\n<polyline fill=\"none\" points=\"344,-332.5 344,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"344,-355.5 402,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"402,-332.5 402,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-363.3\">(None, 1, 1, 128)</text>\n<polyline fill=\"none\" points=\"402,-355.5 519,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-340.3\">(None, 128)</text>\n</g>\n<!-- 140068383036192&#45;&gt;140068382442776 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140068383036192-&gt;140068382442776</title>\n<path d=\"M259.5,-415.3799C259.5,-407.1745 259.5,-397.7679 259.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-388.784 259.5,-378.784 256.0001,-388.784 263.0001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068382442496 -->\n<g class=\"node\" id=\"node18\">\n<title>140068382442496</title>\n<polygon fill=\"none\" points=\"133.5,-249.5 133.5,-295.5 385.5,-295.5 385.5,-249.5 133.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187\" y=\"-268.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"240.5,-249.5 240.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"240.5,-272.5 298.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"298.5,-249.5 298.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"342\" y=\"-280.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"298.5,-272.5 385.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"342\" y=\"-257.3\">(None, 32)</text>\n</g>\n<!-- 140068382442776&#45;&gt;140068382442496 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140068382442776-&gt;140068382442496</title>\n<path d=\"M259.5,-332.3799C259.5,-324.1745 259.5,-314.7679 259.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-305.784 259.5,-295.784 256.0001,-305.784 263.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068382207504 -->\n<g class=\"node\" id=\"node19\">\n<title>140068382207504</title>\n<polygon fill=\"none\" points=\"55,-166.5 55,-212.5 464,-212.5 464,-166.5 55,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-185.8\">batch_normalization_7: BatchNormalization</text>\n<polyline fill=\"none\" points=\"326,-166.5 326,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"326,-189.5 384,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"384,-166.5 384,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-197.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"384,-189.5 464,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 140068382442496&#45;&gt;140068382207504 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140068382442496-&gt;140068382207504</title>\n<path d=\"M259.5,-249.3799C259.5,-241.1745 259.5,-231.7679 259.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-222.784 259.5,-212.784 256.0001,-222.784 263.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068381335224 -->\n<g class=\"node\" id=\"node20\">\n<title>140068381335224</title>\n<polygon fill=\"none\" points=\"123.5,-83.5 123.5,-129.5 395.5,-129.5 395.5,-83.5 123.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-102.8\">dropout_3: Dropout</text>\n<polyline fill=\"none\" points=\"257.5,-83.5 257.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"257.5,-106.5 315.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"315.5,-83.5 315.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-114.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"315.5,-106.5 395.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-91.3\">(None, 32)</text>\n</g>\n<!-- 140068382207504&#45;&gt;140068381335224 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140068382207504-&gt;140068381335224</title>\n<path d=\"M259.5,-166.3799C259.5,-158.1745 259.5,-148.7679 259.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-139.784 259.5,-129.784 256.0001,-139.784 263.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068380956936 -->\n<g class=\"node\" id=\"node21\">\n<title>140068380956936</title>\n<polygon fill=\"none\" points=\"137,-.5 137,-46.5 382,-46.5 382,-.5 137,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"244,-.5 244,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"244,-23.5 302,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"302,-.5 302,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"342\" y=\"-31.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"302,-23.5 382,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"342\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140068381335224&#45;&gt;140068380956936 -->\n<g class=\"edge\" id=\"edge21\">\n<title>140068381335224-&gt;140068380956936</title>\n<path d=\"M259.5,-83.3799C259.5,-75.1745 259.5,-65.7679 259.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-56.784 259.5,-46.784 256.0001,-56.784 263.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140068496967552 -->\n<g class=\"node\" id=\"node22\">\n<title>140068496967552</title>\n<polygon fill=\"none\" points=\"195,-1743.5 195,-1779.5 324,-1779.5 324,-1743.5 195,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-1757.8\">140068496967552</text>\n</g>\n<!-- 140068496967552&#45;&gt;140068496967664 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140068496967552-&gt;140068496967664</title>\n<path d=\"M259.5,-1743.4092C259.5,-1735.4308 259.5,-1725.795 259.5,-1716.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.0001,-1716.5333 259.5,-1706.5333 256.0001,-1716.5334 263.0001,-1716.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "6BI-J_PB-j6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_a.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              # Adding accuracy metrics \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Obu20RfxoROn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks_list = [\n",
        "    # Interrupts training when improvement stops\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Monitors the model’s validation accuracy\n",
        "        monitor='val_acc',\n",
        "        # Interrupts training when accuracy has stopped \n",
        "        # improving for more than one epoch (that is, two epochs)\n",
        "        patience=5,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Saves the current weights after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        # Path to the destination model file\n",
        "        filepath='depthwise_separable_model.h5',\n",
        "        # These two arguments mean you won’t overwrite the model file \n",
        "        # unless val_loss has improved, \n",
        "        monitor='val_loss',\n",
        "        # which allows you to keep the best model seen during training\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        # Monitors the model’s validation loss\n",
        "        monitor='val_loss',\n",
        "        # Divides the learning rate by 10 when triggered\n",
        "        factor=0.1,\n",
        "        # The callback is triggered after the validation loss \n",
        "        # has stopped improving for 1 epochs.\n",
        "        patience=3,\n",
        "        verbose=1\n",
        "    ) \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8rxpQnUdsqx",
        "colab_type": "code",
        "outputId": "d3dcd716-60d9-4c18-a58f-a0985570a5fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3901
        }
      },
      "cell_type": "code",
      "source": [
        "# Tensorboard\n",
        "\n",
        "#安裝tensorboard colab\n",
        "!pip install tensorboardcolab\n",
        "import numpy\n",
        "from tensorboardcolab import *\n",
        "\"\"\"\n",
        "tbc=TensorBoardColab()\n",
        "\n",
        "callbacks = [\n",
        "    TensorBoardColabCallback(tbc,histogram_freq=1)\n",
        "    \n",
        "] \n",
        "\"\"\"\n",
        "\n",
        "history = model_a.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(x_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.19)\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 30s 590us/step - loss: 1.9846 - acc: 0.3106 - val_loss: 1.4570 - val_acc: 0.4753\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.45696, saving model to depthwise_separable_model.h5\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 27s 538us/step - loss: 1.4492 - acc: 0.4874 - val_loss: 1.2846 - val_acc: 0.5368\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.45696 to 1.28457, saving model to depthwise_separable_model.h5\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 27s 531us/step - loss: 1.2724 - acc: 0.5587 - val_loss: 1.2897 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.28457\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 26s 526us/step - loss: 1.1575 - acc: 0.6012 - val_loss: 1.0142 - val_acc: 0.6481\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.28457 to 1.01422, saving model to depthwise_separable_model.h5\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 27s 531us/step - loss: 1.0734 - acc: 0.6337 - val_loss: 1.0011 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.01422 to 1.00107, saving model to depthwise_separable_model.h5\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 27s 540us/step - loss: 1.0131 - acc: 0.6547 - val_loss: 0.9146 - val_acc: 0.6866\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.00107 to 0.91464, saving model to depthwise_separable_model.h5\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 27s 549us/step - loss: 0.9717 - acc: 0.6719 - val_loss: 0.9471 - val_acc: 0.6768\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.91464\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 27s 546us/step - loss: 0.9235 - acc: 0.6861 - val_loss: 0.8520 - val_acc: 0.7059\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.91464 to 0.85196, saving model to depthwise_separable_model.h5\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 28s 551us/step - loss: 0.8946 - acc: 0.6983 - val_loss: 0.8555 - val_acc: 0.7084\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.85196\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 27s 547us/step - loss: 0.8626 - acc: 0.7098 - val_loss: 0.7978 - val_acc: 0.7246\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.85196 to 0.79782, saving model to depthwise_separable_model.h5\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 27s 546us/step - loss: 0.8316 - acc: 0.7189 - val_loss: 0.7917 - val_acc: 0.7225\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.79782 to 0.79168, saving model to depthwise_separable_model.h5\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 27s 541us/step - loss: 0.8139 - acc: 0.7274 - val_loss: 0.7837 - val_acc: 0.7306\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.79168 to 0.78372, saving model to depthwise_separable_model.h5\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 26s 529us/step - loss: 0.7903 - acc: 0.7364 - val_loss: 0.7734 - val_acc: 0.7355\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.78372 to 0.77344, saving model to depthwise_separable_model.h5\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 27s 536us/step - loss: 0.7704 - acc: 0.7409 - val_loss: 0.7459 - val_acc: 0.7432\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.77344 to 0.74594, saving model to depthwise_separable_model.h5\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 27s 537us/step - loss: 0.7573 - acc: 0.7495 - val_loss: 0.7320 - val_acc: 0.7540\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.74594 to 0.73202, saving model to depthwise_separable_model.h5\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 27s 550us/step - loss: 0.7440 - acc: 0.7507 - val_loss: 0.7276 - val_acc: 0.7563\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.73202 to 0.72761, saving model to depthwise_separable_model.h5\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 27s 547us/step - loss: 0.7249 - acc: 0.7602 - val_loss: 0.7626 - val_acc: 0.7415\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.72761\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 27s 549us/step - loss: 0.7132 - acc: 0.7619 - val_loss: 0.7331 - val_acc: 0.7542\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.72761\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 28s 551us/step - loss: 0.7028 - acc: 0.7674 - val_loss: 0.7269 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.72761 to 0.72688, saving model to depthwise_separable_model.h5\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 27s 549us/step - loss: 0.6944 - acc: 0.7707 - val_loss: 0.6889 - val_acc: 0.7672\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.72688 to 0.68888, saving model to depthwise_separable_model.h5\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 27s 542us/step - loss: 0.6846 - acc: 0.7737 - val_loss: 0.6950 - val_acc: 0.7670\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.68888\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 27s 537us/step - loss: 0.6750 - acc: 0.7770 - val_loss: 0.6659 - val_acc: 0.7753\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.68888 to 0.66587, saving model to depthwise_separable_model.h5\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 27s 536us/step - loss: 0.6646 - acc: 0.7808 - val_loss: 0.6990 - val_acc: 0.7689\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.66587\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 27s 534us/step - loss: 0.6564 - acc: 0.7818 - val_loss: 0.6802 - val_acc: 0.7746\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.66587\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 27s 536us/step - loss: 0.6477 - acc: 0.7857 - val_loss: 0.6733 - val_acc: 0.7729\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.66587\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 27s 549us/step - loss: 0.5946 - acc: 0.8039 - val_loss: 0.6122 - val_acc: 0.7940\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.66587 to 0.61217, saving model to depthwise_separable_model.h5\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 27s 549us/step - loss: 0.5873 - acc: 0.8055 - val_loss: 0.6122 - val_acc: 0.7943\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.61217\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 27s 546us/step - loss: 0.5785 - acc: 0.8097 - val_loss: 0.6083 - val_acc: 0.7969\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.61217 to 0.60831, saving model to depthwise_separable_model.h5\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 27s 547us/step - loss: 0.5746 - acc: 0.8111 - val_loss: 0.6072 - val_acc: 0.7987\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.60831 to 0.60721, saving model to depthwise_separable_model.h5\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 27s 546us/step - loss: 0.5755 - acc: 0.8097 - val_loss: 0.6087 - val_acc: 0.7993\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.60721\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 27s 536us/step - loss: 0.5690 - acc: 0.8121 - val_loss: 0.6047 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.60721 to 0.60466, saving model to depthwise_separable_model.h5\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 26s 528us/step - loss: 0.5654 - acc: 0.8154 - val_loss: 0.6137 - val_acc: 0.7965\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.60466\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 27s 530us/step - loss: 0.5663 - acc: 0.8132 - val_loss: 0.6087 - val_acc: 0.7988\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.60466\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 26s 528us/step - loss: 0.5652 - acc: 0.8138 - val_loss: 0.6088 - val_acc: 0.8000\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.60466\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 27s 545us/step - loss: 0.5541 - acc: 0.8168 - val_loss: 0.6068 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.60466\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 27s 547us/step - loss: 0.5557 - acc: 0.8159 - val_loss: 0.6068 - val_acc: 0.7994\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.60466\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 27s 547us/step - loss: 0.5592 - acc: 0.8152 - val_loss: 0.6063 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.60466\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 27s 545us/step - loss: 0.5530 - acc: 0.8169 - val_loss: 0.6057 - val_acc: 0.8003\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.60466\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 27s 544us/step - loss: 0.5564 - acc: 0.8160 - val_loss: 0.6060 - val_acc: 0.8001\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.60466\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 26s 527us/step - loss: 0.5570 - acc: 0.8156 - val_loss: 0.6064 - val_acc: 0.7994\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.60466\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 27s 534us/step - loss: 0.5551 - acc: 0.8165 - val_loss: 0.6063 - val_acc: 0.7998\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.60466\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 26s 525us/step - loss: 0.5545 - acc: 0.8169 - val_loss: 0.6063 - val_acc: 0.7996\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.60466\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 27s 534us/step - loss: 0.5508 - acc: 0.8175 - val_loss: 0.6061 - val_acc: 0.7991\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.60466\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tvxu7U0uyKxT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_json = model_a.to_json()\n",
        "with open(\"depthwise_separable_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vfcHSVSt-j6-",
        "colab_type": "code",
        "outputId": "48bf5e26-bf9e-40ce-90a6-7927087a53a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "cell_type": "code",
      "source": [
        "model_a.load_weights('depthwise_separable_model.h5')\n",
        "score = model_a.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.6046573032855987\n",
            "Test accuracy: 0.7977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9eL1Lo3wZYey",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#下載模型的視覺化圖檔\n",
        "from keras.utils import plot_model\n",
        "plot_model(model_a, to_file='model_a.png')\n",
        "from google.colab import files\n",
        "files.download('model_a.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lw344gA5Tn_y",
        "colab_type": "code",
        "outputId": "2d8e56fe-e02f-4613-f9d1-4cd649ca3717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "K.image_data_format()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'channels_last'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "99O7NKlcRx8s",
        "colab_type": "code",
        "outputId": "d0bfde57-d98f-4e92-c948-6d709a8e8d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6434c5e3c8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XlcVdXC//HPGTggggoKKk6ZhYZm\n3R4bKAsHcCqfLk3SpGWlN+tJb9ZNvZrmlFqWNvs4dG9pDte0nn6ZpBVlZVlqt1DM4aY5C85wQDjD\n748TKHIOHOTAZvi+Xy9ecPZ0lnvJ+bL2Xnstk9vtdiMiIiJVzmx0AUREROoqhbCIiIhBFMIiIiIG\nUQiLiIgYRCEsIiJiEIWwiIiIQRTCUiuMHz+ePn360KdPHzp27Ej37t2LXmdnZ5frWH369CErK6vU\nbWbOnMnixYsrUuSAe+CBB1ixYkVAjtW+fXsOHTrEmjVrGD16dIXeb9myZUU/+3Nu/TVq1CjeeOON\ngBxLxChWowsgEgjPPfdc0c89evRgxowZdOnS5YKOtXr16jK3GTly5AUdu6ZJSkoiKSnpgvfPzMxk\n3rx53HXXXYB/51akLlFLWOqE+++/n5dffpm+ffuyadMmsrKyeOihh+jTpw89evTg7bffLtq2sBX4\n/fffM2DAAGbOnEnfvn3p0aMHGzZsAIq3wnr06MGSJUu444476Nq1K9OmTSs61ltvvUV8fDy33347\nixYtokePHl7L969//Yu+ffvSq1cv7r33Xvbv3w/AihUreOKJJxgzZgy9e/emX79+7NixA4C9e/dy\n5513kpiYyMiRI3E6nSWO++WXX9K/f/9iy2699Va++uqrUs9BoRUrVvDAAw+U+X6fffYZ/fv3p3fv\n3tx2221kZGQAkJKSwoEDB+jTpw/5+flF5xbgnXfeoV+/fvTp04dHH32UY8eOFZ3bV155hQcffJDu\n3bvz4IMPkpub66tqAdi2bRspKSn06dOHW2+9lXXr1gGQk5PDY489Rt++fenZsydjx46loKDA53KR\nqqYQljojPT2djz/+mKuuuoo333yTli1bsnr1av75z38yc+ZMDh48WGKfrVu3csUVV/DJJ59wzz33\n8Oabb3o99g8//MDSpUt5//33WbhwIYcOHWLHjh3MmzePDz/8kPfee89nK/Do0aNMnDiRt99+m08/\n/ZTWrVsXu8z61Vdfcc8995Camsq1117LP//5TwBefPFF4uPjWbt2LYMGDWLTpk0ljh0fH8+hQ4fY\nu3cv4AnSQ4cOcf311/t9Dgr5ej+Hw8GoUaOYNGkSqamp9OjRg+nTpwMwdepUmjdvzurVq7HZbEXH\n+umnn5g/fz7vvvsuq1evJiYmhpkzZxatX716NS+//DJr1qzh2LFjrFmzxme5XC4XTz75JPfddx+r\nV69m8uTJjBw5kuzsbD744AMaNGjAJ598QmpqKhaLhZ07d/pcLlLVFMJSZyQkJGA2e/7Ljx07lnHj\nxgHQqlUroqKi2LdvX4l96tevT2JiIgAdO3bkwIEDXo/dv39/LBYLTZs2pXHjxhw8eJAffviBa665\nhujoaIKDg7n99tu97tu4cWM2btxIs2bNAOjSpUtRaAK0a9eOTp06ARAXF1cUlD/++CP9+vUDoHPn\nzlx88cUljm2z2ejevTuff/45AGvXriUxMRGr1er3OSjk6/2sVivffvstV155pdfye5OWlkbv3r1p\n3LgxAHfeeSfffPNN0fqEhAQaNWqE1WolNja21D8O9u3bR1ZWFjfffDMAl19+OTExMfzyyy9ERkay\nefNmvv76a1wuF8899xyXXXaZz+UiVU33hKXOaNiwYdHPv/zyS1HLz2w2k5mZicvlKrFPeHh40c9m\ns9nrNgBhYWFFP1ssFpxOJ6dOnSr2nk2bNvW6r9Pp5JVXXuHzzz/H6XSSk5ND27ZtvZah8NgAJ0+e\nLPa+DRo08Hr83r1788477zBo0CDWrl3LsGHDynUOCpX2fu+++y4rV64kPz+f/Px8TCaTz+MAHDt2\njOjo6GLHOnr0aJn/Zl/HCg8PL/aeDRo04NixY9x8882cPHmS2bNn85///If//u//ZvTo0fTt29fr\n8nNb6yJVQS1hqZOefvppevfuTWpqKqtXryYiIiLg7xEWFobdbi96feTIEa/brVq1is8//5yFCxeS\nmprKE0884dfxGzRoUKznd+E91fPdeOONbNu2jd27d7N7926uu+46oPznwNf7bdq0iblz5/Lmm2+S\nmprK5MmTyyx7kyZNOHHiRNHrEydO0KRJkzL386Zx48acPHmSc+eiOXHiRFErOyUlhX/961+sWrWK\nLVu28MEHH5S6XKQqKYSlTjp69CidOnXCZDKxcuVKcnNziwVmIHTu3Jnvv/+eY8eOkZ+f7/ND/ujR\no7Ro0YLIyEiOHz/OJ598Qk5OTpnHv/LKK4vulW7atInff//d63Y2m42uXbvywgsv0LNnTywWS9H7\nlucc+Hq/Y8eO0bhxY2JiYsjNzWXlypXY7XbcbjdWqxW73Y7D4Sh2rG7durFmzRqOHz8OwJIlS0hI\nSCjz3+xNy5YtadasGatWrSoqW1ZWFp07d+b1119n+fLlgOdKRMuWLTGZTD6Xi1Q1hbDUScOHD+ex\nxx6jf//+2O12BgwYwLhx43wG2YXo3LkzycnJJCcnM3DgQLp37+51u1tuuYUTJ06QlJTEyJEjGTFi\nBIcOHSrWy9qbp59+mi+++ILExEQWLVrE9ddf73Pb3r17s3btWvr27Vu0rLznwNf73XjjjURHR5OY\nmMjgwYMZNGgQ4eHhPPHEE7Rv356GDRtyww03FLuf3rlzZ4YMGcK9995Lnz59OH36NH/9619L/ff6\nYjKZeOmll1i4cCF9+/Zl8uTJzJ49m9DQUG699VY+/PBDevfuTZ8+fQgKCuLWW2/1uVykqpk0n7BI\n5XG73UUtrLS0NGbNmqXLniJSRC1hkUpy7NgxrrvuOvbv34/b7eaTTz4p6kEsIgJqCYtUqsWLF7Ng\nwQJMJhMXX3wxU6ZMKeowJCKiEBYRETGILkeLiIgYRCEsIiJikCofMSsz83RAjxcREcrx44F9vlPK\nR3VgPNWBsXT+jVfd6yAqKtzr8hrfErZaLUYXoc5THRhPdWAsnX/j1dQ6qPEhLCIiUlMphEVERAyi\nEBYRETGIQlhERMQgCmERERGD+PWI0owZM9i4cSMOh4OhQ4fSq1evonXffvstL730EhaLhZtuuonH\nHnus0gorIiJSm5QZwt999x07duxg6dKlHD9+nOTk5GIhPHnyZObPn0/Tpk2577776N27N5dcckml\nFlpERKQ2KDOEr776ajp37gxAgwYNyM3Nxel0YrFY2Lt3Lw0bNqR58+YAJCQksH79eoWwiEgd8eqr\nL/PrrxkcO3aUvLw8YmJa0KBBQ6ZOfaHMfVet+oj69cNISPA+1/bs2TO5884UYmJaXFDZHn98CE8+\n+Tcuvrj6ZlKZIWyxWAgNDQVg+fLl3HTTTVgsnoeiMzMziYyMLNo2MjKSvXv3lnq8iIjQgDxUvWQJ\nTJ0KW7dCXFw4Y8ZASkqFDysXyNdoMFJ1VAfGqinnv/hnJxX+7Jw48VkAVqxYwY4dO3jmmWf83nfQ\noHtKXT958oRyleX8OrDZrERE1K/WdeP3sJVr165l+fLlLFiwoEJvGIhhxVautDJ0aL2i17/8Anff\nDadO5ZKc7Kjw8aV8oqLCAz4cqZSP6sBYNeX8V+Zn5+nTedjt+UXnYdOmH1myZCF2u53HH/8rmzdv\nJC3tM1wuF/HxNzB48BDmz59Do0aNaNu2HStWLMNkMrNnz29069aTwYOHFLVkv/jiM3Jysvn99z3s\n37+PJ54YSXz8DSxc+A/Wrv2UmJgWWCyQnDyAq67qUlSm/HwHx4/n8NtvB5kyZQLZ2adxOByMGPE0\n7dt3YNasF9i2LQOn00ly8h3069ff67JA8PWHgF8hvG7dOt566y3mzZtHePjZA0VHR5OVlVX0+vDh\nw0RHR1ewqGWbNcvmdfns2TaFsIiID1X92blr104WL16BzWZj8+aNvPHGPMxmM3fddSsDBhRvBW/d\nuoX33nsfl8vFnXf2Z/DgIcXWHzlymBdffIXvvvuWDz98n44dO7Fixb9YvPh9cnJyuPvu20hOHuC1\nHP/612I6duzEffc9wLZtW3n11ZeYOvUFvv32a5Yt+xCHw8GqVR9x6tTJEssqW5khfPr0aWbMmME/\n/vEPGjVqVGxdy5Ytyc7OZt++fTRr1owvvviCF198sdIKW2j7du9PVvlaLiIiVf/Zeckll2KzeYI/\nJCSExx8fgsVi4cSJE5w6darYtu3bdyAkJMTnsTp3vhLwNP48ubOXiy9uR3BwCMHBIUV9l7zZtm0r\nAwc+BECHDnHs27eXBg0a0qpVG0aNepLu3RPp0+dmbDZbiWWVrcwQXrVqFcePH2fEiBFFy6699lra\nt29PUlISEyZMYOTIkQD069ePtm3bVl5p/xAb6yIjo+R95dhYV6W/t4hITVXVn51BQUEAHDp0kKVL\nF7FgwSJCQ0O5//67Smxb2NfIl3PXu91u3G4wm8/+8WAymXzuazKZcLvdRa9dLs+/d+bMV/j1122s\nWbOa1as/5uWXX/e6rDKVGcIDBgxgwADvTXzw9J5eunRpQAtVlhEj8ovd1yg0fHh+lZZDRKQmMeqz\n88SJE0RERBAaGsqvv27j0KFDFBQUVOiYzZs35z//2YXD4eD06dOkp6f73LZDhzg2b/6RTp0uJz39\nF9q2bcfBgwf4+uuvuPPOFNq378Dgwfd5XVbZqnw+4UDw3LvIZfZsG9u3W4iNdTJ8eL7uB4uIlKL4\nZ6eZ2FhXlXx2XnppLPXqhfLoo4O5/PIrufXW25g5czqdO19xwceMjGxMUlIfHnlkIG3atKVz584+\nW9N33XU3U6c+xxNP/AWXy8WTTz5DkyZRpKf/m88++5SgoCBuvvm/vS6rbCb3uW30KhDoHoQ1pVdi\nbaY6MJ7qwFg6/8ZYteojkpL6YLFYGDz4HmbMmE10dFOji+VVhXpHi4iIVDdHjx5lyJBBBAXZ6N+/\nf7UN4NKoJSwVpjownurAWDr/xqvudeCrJaxnekRERAyiEBYRETGIQlhERMQgCmERERGDKIRFROSC\nDR36INu2ZRRb9tZbr7F48UKv22/a9CNjx/4NgFGjniyx/v33lzJ//hyf77dz5w5+/30PAOPHj+bM\nmbwLLTp33NEfu73ikwpVhEJYREQuWFJSbz7/fE2xZWlpn5OY2KvMfadNe6nc7/fll5+zd+/vADz3\n3PMEB/seb7om0HPCIiJywXr27MWjjz7EsGFPALBtWwZRUVFERUXzww/fM2/eWwQFBREeHs7EidOK\n7XvzzT35+OPP+PHHDbzyykwiIxvTuHETYmJa4HA4mDJlApmZR8jNzWXw4CE0a9acDz9cwZdffk5E\nRATPPjuad95ZSnb2aZ55Zjg5ObmYzWZGjRqHyWRiypQJxMS0YOfOHcTGtmfUqHFe/w1Hjhzm+ecn\nUlBQULR/dHRTJk4cx9GjWeTn5/PQQ0Pp0uWaEsuuu+76Cp0/hbCISC0xYUIwH30U2I/1/v0dTJhw\nxuf6iIhIYmJasHVrOnFxnfj88zUkJfUBPLPwjR8/mZiYFkya9Czff7+e0NDQEseYM+c1xo2bxKWX\nxvLUU08QE9OC06dPcc0119G37y3s37+PceNGsWDBQq69Np5u3XoSF9epaP95897ijjvu4Oqrb+SL\nL9ayYMH/8tBDQ/n11wyee24qERGRJCf34/Tp08Wm4z13/1tuuZWePXsV7X/nnXdz8uQJXn99LqdP\nn2b9+m/YtWtniWUVpcvRIiJSIUlJffjsM88l6W+++Ypu3XoC0KhRI6ZPn8zjjw9h8+aNnDp10uv+\nBw8e5NJLYwG48sqrAAgPb0BGxhYefXQwU6ZM8LkvwK+/ZnDNNdcAcNVVXdix41cAWrRoRePGTTCb\nzTRpEkVOTrbP/f/0p/8qtn+bNhdht+cwadI4Nm36gcTEXl6XVZRawiIitcSECWdKbbVWloSE7rzz\nzgKSknrTqlVrGjRoAMDzz0/ihRdmcdFFbXnppek+9z93SsLCQRzXrFnNqVOneP31eZw6dYqHH76/\nlBKcnaqwoMCByeQ53vkTOvgeILLk/iEhIcyZ8w9++eVnPvnkI775Zh1jxoz3uqwi1BIWEZEKCQ2t\nT7t2l/LOO28XXYoGyMnJpmnTZpw+fZpNmzb6nL6wSZMofv99N263m82bNwKe6Q+bN4/BbDbz5Zef\nF+1rMplwOp3F9r/ssji+//57AH76aSMdOlxWrvJfdlkcmzb9WGz/wjmFr7jiSp56ajS7d//mdVlF\nqSUsIiIVlpTUh8mTxzN+/KSiZbfddiePPvoQrVq15t57B7Jgwf8yZMiwEvsOGTKMsWOfoVmz5kWT\nMHTr1oNRo55k69Z0br75v4mOjubtt+dyxRV/YtasF4rdW3744b8wc+ZUFi1ajNUaxOjR43A4/J+e\n8eGH/8Lzz0/io48+KNo/ODiEOXNe58MPV2A2m7nnnvtp3jymxLKK0gQOUmGqA+OpDoyl82+86l4H\nmsBBRESkmlEIi4iIGEQhLCIiYhCFsIiIiEEUwiIiIgZRCIuIiBhEISwiImIQhbCIiIhBFMIiIiIG\nUQiLiIgYRCEsIiJiEIWwiIiIQfwK4e3bt5OYmMjChQtLrFu0aBEDBgzg7rvvZsqUKQEvoIiISG1V\nZgjb7XYmTZpEfHx8iXXZ2dnMnz+fRYsWsXjxYnbt2sVPP/1UKQUVERGpbcoMYZvNxty5c4mOji6x\nLigoiKCgIOx2Ow6Hg9zcXBo2bFgpBRUREaltrGVuYLVitXrfLDg4mMcee4zExESCg4O5+eabadu2\nbanHi4gIxWq1XFhpffA1T6NUHdWB8VQHxtL5N15NrIMyQ7g02dnZzJkzh9WrVxMWFsagQYPYtm0b\nHTp08LnP8eP2irxlCdV9Iue6QHVgPNWBsXT+jVfd68DXHwgV6h29a9cuWrVqRWRkJDabjS5dupCe\nnl6RQ4qIiNQZFQrhFi1asGvXLvLy8gBIT0/noosuCkS5REREar0yL0enp6czffp09u/fj9VqJTU1\nlR49etCyZUuSkpJ46KGHGDhwIBaLhT/96U906dKlKsotIiJS45ncbre7Kt8w0Nfsq/t9gLpAdWA8\n1YGxdP6NV93roFLuCYuIiMiFUwiLiIgYRCEsIiJiEIWwiIiIQRTCIiIiBlEIi4iIGEQhLCIiYhCF\nsIiIiEEUwiIiIgZRCIuIiBhEISwiImIQhbCIiIhBFMIiIiIGUQiLiIgYRCEsIiJiEIWwiIiIQRTC\nIiIiBlEIi4iIGEQhLCIiYhCFsIiIiEEUwiIiIgZRCIuIiBhEISwiImIQhbCIiIhBFMIiIiIGUQiL\niIgYRCEsIiJiEIWwiIiIQRTCIiIiBvErhLdv305iYiILFy4sse7gwYPcfffd3HHHHTz77LMBL6CI\niEhtVWYI2+12Jk2aRHx8vNf106ZNY/DgwSxfvhyLxcKBAwcCXkgREZHaqMwQttlszJ07l+jo6BLr\nXC4XGzdupEePHgCMHz+emJiYwJdSRESkFrKWuYHVitXqfbNjx45Rv359nn/+ebZs2UKXLl0YOXJk\nqceLiAjFarVcWGl9iIoKD+jxpPxUB8ZTHRhL5994NbEOygzh0rjdbg4fPszAgQNp0aIFQ4YMIS0t\njW7duvnc5/hxe0XesoSoqHAyM08H9JhSPqoD46kOjKXzb7zqXge+/kCoUO/oiIgIYmJiaN26NRaL\nhfj4eHbs2FGRQ4qIiNQZFQphq9VKq1at2L17NwBbtmyhbdu2gSiXiIhIrVfm5ej09HSmT5/O/v37\nsVqtpKam0qNHD1q2bElSUhJjxoxh1KhRuN1uYmNjizppiYiISOlMbrfbXZVvGOhr9tX9PkBdoDow\nnurAWDr/xqvudVAp94RFRETkwimERUREDKIQFhERMYhCWERExCAKYREREYMohEVERAyiEBYRETGI\nQlhERMQgCmERERGDKIRFREQMohAWERExiEJYRETEIAphERERgyiERUREDKIQFhERMYhCWERExCAK\nYREREYMohEVERAyiEBYRETGIQlhERMQgNTqE8/LgvfcgP9/3NitXWklICKV58zASEkJZudJadQUU\nEREpRY0O4S++sHLvvbBwYZDX9StXWhk6tB4ZGRacThMZGRaGDq2nIBYRkWqhRodw585OAD791Huo\nzppl87p89mzvy0VERKpSjQ7hFi3cXHEFfP21hezskuu3b/f+z/O1XEREpCrV+DS65RbIzzexbl3J\n1nBsrMvrPr6Wi4iIVKUaH8I33+z5vnatpcS6ESO899gaPryUnlwiIiJVpMaH8DXXQOPGLj791Irb\nXXxdcrKDOXNyiYtzYrW6iYtzMmdOLsnJDmMKKyIico4a303YYoGePZ0sWxbEL7+Y6dy5+KXm5GSH\nQldERKqlGt8SBkhK8oTsmjU1/m8KERGpQ/wK4e3bt5OYmMjChQt9bjNz5kzuv//+gBWsPLp1c2C1\nuhXCIiJSo5QZwna7nUmTJhEfH+9zm507d/LDDz8EtGDl0bAhXHedk02bLBw5YjKsHCIiIuVRZgjb\nbDbmzp1LdHS0z22mTZvGX//614AWrLwSEz2XpD/7rGQvaRERkeqozOu3VqsVq9X3ZitWrOCaa66h\nRYsWfr1hREQoVmtggzIqKpyUFJgwAb76qh5PPBHQw4sfoqLCjS5Cnac6MJbOv/FqYh1U6CbqiRMn\nWLFiBW+//TaHDx/2a5/jx+0VecsSoqLCycw8TUQEtG1bn9WrTezfn41NI1NWmcI6EOOoDoyl82+8\n6l4Hvv5AqFDv6O+++45jx45x77338vjjj7NlyxamTp1akUNeMJMJevVykJNjYv16XZIWEZHqr0Ih\n3KdPH1atWsWyZct47bXX6NixI2PGjAlU2cqt8L7w2rXqJS0iItVfmWmVnp7O9OnT2b9/P1arldTU\nVHr06EHLli1JSkqqijL6LT7eSf36blJTrUyceAaTOkqLiEg1VmYId+rUiXfffbfMA7Vs2dKv7SqT\nzQbduzv4f/8viF27TFxyibvsnURERAxSK0bMOpdGzxIRkZqi1oVwz55OQCEsIiLVX60L4ehoN1dd\n5eS77yycOmV0aURERHyrdSEMnl7SDoeJtDS1hkVEpPqqlSHcq5fnvvCnnyqERUSk+qqVIXz55S6a\nNXPx2WcWnE6jSyMiIuJdrQxhk8lzSfroUTObNtXKf6KIiNQCtTahkpI8TWCNniUiItVVrQ3hG290\nEBzs1n1hERGptmptCIeFwfXXO9myxcL+/Rq/UkREqp9aG8Jwtpe0LkmLiEh1VKtDuHBWJY2eJSIi\n1VGtDuE2bdy0b+9k3ToLublGl0ZERKS4Wh3C4JnQITfXxDffWIwuioiISDG1/jptr15OXnvNM3pW\nYqIThwMyM00cOmTi8GEThw+bOXTIxJEjJjIzTdx7bwG9e2uEDxERqXy1PoS7dHHSqJGbJUuC+Phj\nK1lZJtxu372lV6+2ctllLkaMyCc52VGFJRURkbqm1oew1QoDB+azYIGNsDC45BInTZu6//hy0ayZ\nmx07zLz8cvAfe5jIyLAwdGg9IFdBLCIilabWhzDA2LH5jB2b73N9QkKo1+WzZ9sUwiIiUmlqfccs\nf2zf7v00+FouIiISCEoZIDbWVa7lIiIigaAQBkaM8H6pevhw35ewRUREKkohDCQnO5gzJ5e4OCfg\nJijIzZw56pQlIiKVSyH8h+RkB2lpdrp3d1JQYKJbNwWwiIhULoXweTp18gzUsXWrRtgSEZHKpRA+\nT8eOns5Y6ek6NSIiUrmUNOfp1MkTwlu2qCUsIiKVSyF8nosvdhES4mbLFp0aERGpXEqa81it0KGD\ni19/NVNQYHRpRESkNlMIe9Gpk5P8fBM7duj0iIhI5fErZbZv305iYiILFy4sse67777jrrvuIiUl\nhdGjR+Ny1fxRpgo7Z+mStIiIVKYyU8ZutzNp0iTi4+O9rn/22Wd55ZVXWLJkCTk5Oaxbty7ghaxq\nZ3tIq3OWiIhUnjJD2GazMXfuXKKjo72uX7FiBc2aNQMgMjKS48ePB7aEBvCMnKWWsIiIVK4ypzK0\nWq1Yrb43CwsLA+DIkSN88803DB8+vNTjRUSEYrUGtoUZFRUe4ONB27awdauVJk3CMZkCevhaKdB1\nIOWnOjCWzr/xamIdBGQ+4aNHj/KXv/yF8ePHExERUeq2x4/bA/GWRaKiwsnMPB3QYwJcdlkIq1YF\nkZ6eTbNm7oAfvzaprDoQ/6kOjKXzb7zqXge+/kCo8PXW7OxsHnnkEUaMGEHXrl0rerhqQ52zRESk\nslU4YaZNm8agQYO46aabAlGeakOds0REpLKVeTk6PT2d6dOns3//fqxWK6mpqfTo0YOWLVvStWtX\nPvjgA/bs2cPy5csBuOWWWxgwYEClF7yyFU7koJawiIhUljJDuFOnTrz77rs+16enpwe0QNVFq1Zu\nGjQoPnzlypVWZs2ysX27mdhYFyNG5GvOYRERuWAB6ZhVG5lMnkeVNmywYLdDaqqVoUPrFa3PyLD8\n8TpXQSwiIhdE11pL0amTC5fLxLZtZmbNsnndZvZs78tFRETKohAuxbmds7Zv936qfC0XEREpixKk\nFOd2zoqN9T4mtq/lIiIiZVEIl6J9excWi6dz1ogR+V63GT7c+3IREZGyKIRLERICl1ziYssWC7fe\n6mDOnFzi4pxYrW7i4pzMmaNOWSIicuHUO7oMHTu6+PVXC3v2mEhOdih0RUQkYNQSLoNGzhIRkcqi\nEC5Dx44aOUtERCqHkqUMnTp5WsJbt+pUiYhIYClZyhAd7SYqyqXL0SIiEnAKYT906uRi3z4zJ04Y\nXRIREalNFMJ+KLwvvHWrWsMiIhI4CmE/nO0hrdMlIiKBo1TxQ2HnrC1b1BIWEZHAUQj7oV07F8HB\nbr9bwitXWklICKV58zASEkJZuVJjooiISElKBz9YrdChg4uMDDMFBRAU5HvblSs177CIiPhHLWE/\nderkJD/fxM6dpZ8yzTssIiLfuxv0AAAeYElEQVT+Ugj7yd/OWZp3WERE/KVk8JO/nbM077CIiPhL\nIeynuDjPs8JltYQ177CIiPhLIeynBg2gdWsXW7eacbt9b5ecrHmHRUTEP+odXQ4dOzr55JMgjhwx\n0bSp7yTWvMMiIuIPtYTLQSNniYhIIClNyqEwhDVyloiIBIJCuBw6dfJ0ztqyRadNREQqTmlSDq1b\nuwkP93/4ShERkdIoTcrBZPJ0ztq1y4zdXvHjaYxpEZG6za8Q3r59O4mJiSxcuLDEum+//ZY77riD\nAQMG8Prrrwe8gNVNx44uXC4TK1YEkZ194ccpHGM6I8OC02kqGmNaQSwiUneUGcJ2u51JkyYRHx/v\ndf3kyZN59dVXWbx4Md988w07d+4MeCGrky5dPPeFn3wyhNjYMG65pR7Tptn45hsLeXn+H0djTIuI\nSJnNLpvNxty5c5k7d26JdXv37qVhw4Y0b94cgISEBNavX88ll1wS+JJWE7fd5iAqys5XX1n4+msr\nP/5oYcMGKy+9BCEhbq6+2smNNzrp2tXBlVe6sPo4wxpjWkREygxhq9WK1UeSZGZmEhkZWfQ6MjKS\nvXv3Bq501ZDJBDfd5OSmm5xAPqdOwfr1nkBet87CunVW1q2zAsFceqmT1FQ7YWEljxMb6yIjo+Sj\nThpjWkSk7qjyG5AREaFYrYF9zjYqKjygxyvfe0O7dnDffZ7XmZmQlgYLF8L//Z+FN98MZ8aMkvs9\n+yzcfXfJ5ePGWQz991yomljm2kZ1YCydf+PVxDqoUAhHR0eTlZVV9Prw4cNER0eXus/x4wHoVnyO\nqKhwMjNPB/SYFdWtG1x7Lfz0U31mzTKRnJzDJZcUH+ayZ0+YM8fK7Nk2tm83ExvrYvjwfHr2dJCZ\naUy5L1R1rIO6RnVgLJ1/41X3OvD1B0KFbkC2bNmS7Oxs9u3bh8Ph4IsvvuCGG26oyCFrjXr14Lnn\nzlBQYOLvfw/xOulDcrKDtDQ7Bw5kk5Zm9zretB5jEhGpvcr8RE9PT2f69Ons378fq9VKamoqPXr0\noGXLliQlJTFhwgRGjhwJQL9+/Wjbtm2lF7qm6NfPQUKCgy++sLJ6tZW+fcs3qUPhY0yFCh9jAs3K\nJCJSG5jc7tIm5gu8QF8uqO6XIHbsMJOQEEpMjJt163KoV6/sfQolJIR67bwVF+ckLS2wl/UrorrX\nQV2gOjCWzr/xqnsdVMrlaCnbpZe6eOSRAn7/3cwbb5TvGWA9xiQiUrvp07wKPPXUGaKjXbzyio29\ne01+7+frcSU9xiQiUjsohKtAeDiMG3eG3FwTEyYE+73fiBH5XpcPH+59uYiI1CwK4Spy550OunRx\n8tFHQXz1lX/PSScnO5gzJ5e4OCdWq5u4OCdz5qhTlohIbaEQriJmM0yblofJ5Obvfw+moMC//f78\nZwdPPJFPz55O/vEPBbCISG2iEK5CnTu7uO++An791cKCBUFlbr93r4l77qnHX/5Sj9RUK+PH+38p\nW0REqj+FcBUbMyafRo3czJgRzJEj3jtpOZ0wZ04QN95Yn88+s5KQ4OBPf3LyySdB/PCDqkxEpLbQ\nJ3oVa9zYzTPPnOH0aRNTppRs2aanm+nXL5Rx40IICXHz6qu5LFuWy8SJZwCYPDnY6+hbGllLRKTm\nUQgbYNCgAuLinCxeHMTGjZ4qyM2FKVNs9OoVyubNFm6/vYCvv7YzYIADkwmuvdZJ794O1q+38tln\nxTt2FY6slZFhwek0FY2spSAWEaneFMIGsFrh+ec9LdsxY0L46isL3brVZ/bsYJo3d7NkiZ0338yj\nSZPiTd4xY85gMrmZPDkY1zmPCs+a5X0QkNmzyzc4iIiIVC2FsEHi453cdlsBmzdbuOOOUPbsMfGX\nv+Tz1Vc59Ojh9LrPZZe5uOsuB1u3Wnj//bOtXI2sJSJSM+lT2kDjx5+hSRMXHTs6Wb3azsSJZ6hf\nv/R9/va3M9hsbqZPD+aMpzGtkbVERGoohbCBmjd3s3lzDp9/bufKK/0LzFat3Dz4oGcs6n/+0/OY\nU3lG1lIHLhGR6kMhbLDgYDD5P5w04And8HA3L79s4/Rp/0fWUgcuEZHqRSFcAzVu7Oaxx/I5evTs\nzEzJyQ7S0uwcOJBNWprd68ha6sAlIlK9KIRrqKFD84mKcvHmmzafg36cTx24RESqF3361lD168PI\nkfnY7SZeftm/lqw6cImIVC8K4Rrs/vsLuOgiF++8E8Rvv5XdGtbUiCIi1YtCuAYLCoLRo89QUGBi\n+vSyJ3coTwcu9aAWEal8Jrfb20jElScz83RAjxcVFR7wY9YkLhckJYXyyy8WPvssh8svr9il5cIe\n1OcrbR7jul4H1YHqwFg6/8ar7nUQFRXudblawjWc2Qzjxp2d3KGi1INaRKTq6DpjLdCtm5Mbb3Tw\nxRdWvv7aQteunmEvXS44dQpOnDBx4oSJ48c937OzTfTs6SAmpuRFEPWgFhGpOgrhWmLcuDP06mXl\nkUdCaNDAE7wnT4LL5b3DVrNmLj75xE6LFsWDODbWRUaGpcT26kEtIhJ4CuFa4sorXQwcmM+yZUFY\nrW6io13ExrqJiHDTqBE0auQu+tq928xbb9m4++56fPSRnYYNzx5nxIh8r/eE1YNaRCTwFMK1yIsv\nnuHFF8+UuZ3bDQ4HzJtn44EH6rFkSS7Bf9xO9nS+ymX2bBvbt5uJjXUxfHi+105ZK1damTXLxvbt\nEBsbyogR3rcTERHv1Du6jnI64eGHQ/j44yCSkwt48808zOW47Xshvail8uj3wFg6/8ar7nWg3tFS\njMUCb7yRx9VXO1m5MojJk8vX+1m9qEVEKk4hXIfVqwfvvmunXTsXr70WzPz5QX7vW55e1Br8Q0TE\nO4VwHRcZCUuW2ImKcjFmTDAff+xfQPo7DrWmTxQR8c2vEJ46dSoDBgwgJSWFn3/+udi6RYsWMWDA\nAO6++26mTJlSKYWUytWmjZv33sulXj149NEQNmwo+7+Fv+NQ67K1iIhvZX7abtiwgT179rB06VKm\nTJlSLGizs7OZP38+ixYtYvHixezatYuffvqpUgssleOKK1zMn59LQQHcf38oO3eWPiFE8XGo8TkO\ntQb/EBHxrcxPwvXr15OYmAhAu3btOHnyJNnZ2QAEBQURFBSE3W7H4XCQm5tLw3MfOpUapWdPJzNn\n5nH8uImUlNAy5ylOTnaQlmanoADS0uxee0Vr+kQREd/KDOGsrCwiIiKKXkdGRpKZmQlAcHAwjz32\nGImJiXTv3p0rrriCtm3bVl5ppdLdc4+Dp58+w++/m7nnnnosWeIZCvO330zkX8B4Hf5etlbnLRGp\ni8r9SXfuY8XZ2dnMmTOH1atXExYWxqBBg9i2bRsdOnTwuX9ERChWa8lhESvC1/NXcmGmT4djx2D+\nfAtPPHH2WWCTCZo3hzZtoHVrz/c2baBtW+jQIZw2bSjxrPGQIdCgATz/PGzdCnFxMHo0pKScPe6S\nJTB06Nl9CjtvNWgAKSmV/a+tPfR7YCydf+PVxDooM4Sjo6PJysoqen3kyBGioqIA2LVrF61atSIy\nMhKALl26kJ6eXmoIHz9ur2iZi6nuD2jXVFOmQP/+Fn77zczevSb27TOzb5/n+w8/mFi/vuSl6pAQ\nNxdf7OLSS11cconn+6WXurjuOhdr1xbf9o+LKQBMnBgKlPzDbNIkJz17Bvb/S22l3wNj6fwbr7rX\nga8/EMoM4RtuuIFXX32VlJQUtmzZQnR0NGFhYQC0aNGCXbt2kZeXR0hICOnp6SQkJAS25GIIsxmu\nv97J9dc7S6xzOuHwYRN793qCOTOzHj/9VMDOnWZ27jSzdWvJQG3Z0kXHji46d3Zy5ZVOrrjCRXS0\n56qKOm+JSF1VZghfddVVdOzYkZSUFEwmE+PHj2fFihWEh4eTlJTEQw89xMCBA7FYLPzpT3+iS5cu\nVVFuMZDFAjExbmJinFx7LURFQWZmHuCZPvHgQRM7dngCufD79u1mUlOtpKae/S/XvLmLK65wEhnp\nJjOzZMvaW+ets+NVe8a11njVIlKTaexoqTB/6+DwYRM//2zmp58s/Pyzhc2bzRw54ru1e/4jTxqv\n2jf9HhhL59941b0ONHa0GK5pUzdJSU6efjqfd9/NJT09h59/zubdd+3cfHMBYWFuwPM3YVSUC5PJ\n07IuVJ6BP9TbWkRqAoWwGKpZMze9ezt5++08/vOfbLZsyeHhh/M5ccLEkCH16N07lK++8txj9vfe\ncaCHyszOhtGjg3nwwRDdpxaRgNInilQrUVFupk49w9df53DbbQX8+98W7rgjlLvuqkfr1v4N/BHI\noTLXr7fQrVt95s+38fHHQSQkhDJ2bDAnTpT7UCIiJSiEpVpq29bNW2/lsXZtDgkJDtLSrPz2m/fn\ny88f+KM8LWZfl6zz8mDChGD+/Od67NtnYsSIM7z9di6tWrn53/+1ER9fn3/+Mwhnyc7jIiJ+UwhL\ntda5s4t//SuXZcvsdO5cmHhuTCY3LVs6mTWrZKcsf4bKLO2S9c8/m+nVK5Q33rBx0UVuPvrIzpgx\n+dx8s4N163IYN+4MeXkmnn46hMTEUL79NrCDz4hI3aEQlhqhWzcnn35qZ86cXNq0ceN2m9i3z8LI\nkSHccks9XnzRxo8/mnE4/Bsq09cl67Fjg+nTJ5Rt2yw8+GA+n3+ew9VXnw3v4GD4n//J57vvckhJ\nKWDLFgt//nMoDz8cwt69pY+1LSJyPj2iJBVW1XXgcMDGjRbS0iykpVnZvNmMy+UJwIYN3XTt6qBR\nIzfff+8Z8at9exfDhxd/nrh58zCcTu+h2by5i1mz8uje3dPyLu3Z5E2bzPz97yFs3GghJMTNsGH5\n3HVXAS1auAkOruQTcQ79HhhL59941b0OfD2ipBCWCjO6Dk6cgHXrrKSlWfjySyu//372Ak9IiJuo\nKDdNmpz75WLp0iCvzyg3bOjihx9yaNTI89qfZ5NdLnj/fSuTJgVz6NDZYzZt6qJlSzetWrlo1ers\nz4Xf69cP3Dkwug7qOp1/41X3OrjgYStFqrtGjaB/fwf9+ztwu8/w228m0tKsrFtnYd8+M1lZJrZu\nNXPmTNmXi2fMOFMUwFB6T+vCEDab4c47HTgcMGVKMJmZJurV8wzv+e9/m9m4seQ9Y5vNzahRZxg2\nrKDEpBciUncohKVWMZng4ovdXHxxAYMHFxQtd7s9z/tmZprIyjKRlWVmzRoLn35qJSvLxCWXuHjq\nqZJDYJanp/Xw4WdbzHY72O0m3nwzl/h4J3v3np0IY+9eE6mpViZODGH9eiuvvJJH48ZVekFKRKoJ\nhbDUCSYThIdDeLibiy92Ay769XMAZ0rdLzbWRUZGyZasv88mv/qqjdtvtxeNs71ypZWVK21kZZmo\nX9/NmjVWevYM5a238rjuOj3vJFLX6EKYSCn86WkN/rWYz30syuUykZPjuTx+8KCJ5OR6zJ5tKzZM\np4jUfgphkVIkJzuYMyeXuDgnVqubuDin1wkj/Hk22VdruXVrz7SOU6YEc/fd9cjMNGnsa5E6Qr/Z\nImVITnaUOUvTiBH5XntRn9ti9tVa3r/fzC+/5PD44yF89pmV66+vz8mTZzuRFQ4kApU7W1RODrzy\nio2DB838+c8F3HSTE6s+IUQqlX7FRALAE465zJ599nni859NLu3+cuPGbhYtyuX1121MmuS9xTxl\nio3cXNi718y+fWb27zexbZuZo0dNuN1w8cWhPPPMhc2v/OWXnoFPCh/vWrIkiOhoF7ff7mDAgALi\n4nSdXKQy6DlhqTDVgX/8nQ+5WbOwosFHLsRLL+Vy333+BfGJE54xst97z4bF4uaxx/JJSnKyYoWV\nlSuDOHHCU45OnZzcdVcBt93mIDpaPbnPp98B41X3OtB8wiIG8/f+cvv23ludTZq4mDUrl+XL7Xz3\nXTbt23vvTf300yEsWBCE44/D+rq//PHHVrp2rc9779no1MlJaqqdsWPzufZaJ9Onn+GXX7JZsCCX\nPn0K2LbNzLPPhnDFFfW59956fPihlcOHPS1wEblwaglLhakOAsvfFrPvoTfdgIkOHZz07u1g9uyS\n42f+13852LjRSnCwm6eeymfYsHyCgnyXKSvLxAcfWFm2LIiffjp7Sb1ePTetW7u46CI3bdq4uOgi\nF23auGjTxrM8JKQ8//KaS78DxqvudaBhK6XSqA4Cb+VKa6n3lwESEkJ93GN2cu21ThYuDMLt9n1Z\n++qrncyalcell7qK3tPXGNnn2rbNzIcfWtm+3czu3Z6v06e9v8+llzqZOzev1t9T1u+A8ap7HSiE\npdKoDoxRVov5l1/M9OwZCpQMSLPZzYED2UVDZvrb+i7c9tywHj48n27dHOzZ4wnkPXvM7Nlj4rff\nzHz7rZVWrVysXm0nKqr2XrvW74DxqnsdKISl0qgOjHO2xWwhNtZZosV8002eaRnPFxfnJC3NXvTa\nV6v6/O3KE9YAM2famD49mGuucfD++7lVOrNUVdLvgPGqex2oY5ZILZSc7CAtzU5BAaSl2UsE4V//\nGrgRv6D0CS3OVdgZ7IUXbDRo4GLDBitPPRWijlwi51EIi9RigRzxCy5seM5Tpzzrli4N4vXXS+n9\nJVIHKYRFarnC1vKBA9leW8vg/xjZFRme02p1M2lSMKtXl7zsLVJXKYRFxO8Wsz9h7au17HZDSAg8\n+mg9tmzRR48IKIRF5A/+tJj9CWtfreX27V289loeOTkm7r/fM1GFSF2nEBaRcikrrEtrLffv7+CZ\nZ86wb5+ZBx8M4Uzp0zmL1HoKYREJqLJay08+mU9ycgEbNlgZOVI9pqVu0yxKIhJwpU3/aDLBrFl5\n7N5tZtmyINq3d/E//+O99SxS2/kVwlOnTuXf//43JpOJMWPG0Llz56J1Bw8e5Mknn6SgoIC4uDgm\nTpxYaYUVkdqhXj14551cevUKZfJkGyEhblq1Kntoy/BwiIx0ExnpJiLCjc17R+xqw+GA334zk5Fh\nZutWM7m5Jpo2ddG0qZumTd00a+b5OSzM88eJ1D1lhvCGDRvYs2cPS5cuZdeuXYwZM4alS5cWrZ82\nbRqDBw8mKSmJ5557jgMHDhATE1OphRaRmq9pUzfvvptL//6h/P3vFzbTQ1iYuyiUC4O5USNPONts\nbqxWsNn44/vZ10FBnmvgeXkm8vPPfj9zBs6cMXHmDOTnQ36+qeg9mjQp/l6NG3u+h4R4en4fPmxi\n61ZP4GZkWMjIMPPrr2bOnCk7XUND3URHu2na1EV0tKf8516mL/zZ7T77s8nk+WOmXj130ffQUM/P\nhd/r1XOXOjHH+SwWz5fZXPjlLnp97nLPdu5zfj673moFk8mNy2XC5Tpb5sKfXa7iP3u+m4qtO3e/\nc8/DuX+onP9HS2QkHDtW8g6rt9sdhfuaTN6/mjTx1G9VKDOE169fT2JiIgDt2rXj5MmTZGdnExYW\nhsvlYuPGjbz00ksAjB8/vnJLKyK1yq5dZpo1c7F7t5moKDc33eTk8su9T9HodsOpUyaOHzdx7NjZ\nr+PHTWzbZiYvz5imZP36ntA8fjys2PKQEDft27u47DIXcXFOLrvMRXi4m8OHzRw+bDrn6+zrH36w\nVGguaakfkKMEBbn5+eecKgniMkM4KyuLjh07Fr2OjIwkMzOTsLAwjh07Rv369Xn++efZsmULXbp0\nYeTIkZVaYBGpHc4fh/rIERPLl5tJSip5P9mfGZ7sdjh2zMTJkyYKCjwtWYfD9Md3T6u2oICiL4Dg\n4MIvN8HBnlZySIgnVIODPa3I7GwTR496At/b96NHTTgcFq67ruCPwPWEbtu2nlZkSb4vuzsccPSo\nCecff4cUtswKfy5kMnlai3l5YLebyM2F3Nyz3+32s9+9T3fppVQucDrPfne7z31tKlpe+FW4vPhr\nispuNnvKWdh6LlxWuNxkOtuaPnfdufud++/31qI99wpBaKiN3NyzfQtKu7x/bivb21fTpp6rKlWh\n3B2zzp3vwe12c/jwYQYOHEiLFi0YMmQIaWlpdOvWzef+ERGhWK2BHTHH18DYUnVUB8araXXw2mve\nl7/+ej2GDDn7eskSGDr07OuMDAtDh9ajQQNISSm+b5s2gS+n/wIzJGfz5gE5TB0VyE4CVTPbSJkh\nHB0dTVZWVtHrI0eOEBUVBUBERAQxMTG0bt0agPj4eHbs2FFqCB8/bve57kJU95kz6gLVgfFqYh1s\n3RqGt2kWt251k5mZXfR64sRQoOQf7pMmOenZs/gMT/7Mh1wZauL5r22qex1c8CxKN9xwA6mpqQBs\n2bKF6OhowsI89z6sViutWrVi9+7dRevbtm0boCKLSG1WWZNGOJ2motbyypUl2xmFMzw1bx5GQkKo\n123Ks51IRZQZwldddRUdO3YkJSWFyZMnM378eFasWMGaNWsAGDNmDKNHjyYlJYXw8HB69OhR6YUW\nkZqvKiaN8DbFoj9hXZ7tEhJCsVoJSKD7s53+OKhdTG531Y5XE+jLBdX9EkRdoDowXk2tg5Urrcye\nffYS8vDhJS8hn9+Bq9C5o3A1bx7mtQOS1ermwIGzl7YTEkLJyCh5aTsuzklamr1c2/lTrkBv5++x\n6qLq/jtwwZejRUQqS2VPGnEhl7b93c7f1ncgt/P3WOVhROs7kO/p79WI6kohLCLVXkUmjTiXv2Ht\nz3aBDHR/t/P3WOB/0JV12T3Q99sD+Z7FtyMgZavqS/0KYRGp8QI5H7K/2wUy0P3dzt9j+RtigWx9\nG/GegSxbef7YCCSFsIjUCoG6tO3vdoEMdH+38/dY/oZTIFvfRrxnIMtWGZf6/VGzLp6LiFRQaTM8\nlWc7z7rcPzqWWYiNdXrtWFZ8O98d0PzZzt9j+RtOsbEurx3Qzm99l7WNUe8ZyLKV51J/IKklLCJy\ngQpb3wUF+Gx9n7tdaa10f7fzZxt/L1sHsvVtxHsGsmz+lj/QFMIiIrWMv+Hkz2X3QN9vD+R7Ft+O\nCpXN3/IHmp4TlgpTHRhPdWCs6nj+/XkGuza8Z6Gy6sDfZ9Irq/y+nhNWCEuFqQ6Mpzowls6/8ap7\nHWiwDhERkWpGISwiImIQhbCIiIhBFMIiIiIGUQiLiIgYRCEsIiJiEIWwiIiIQRTCIiIiBlEIi4iI\nGKTKR8wSERERD7WERUREDKIQFhERMYhCWERExCAKYREREYMohEVERAyiEBYRETGI1egCVMTUqVP5\n97//jclkYsyYMXTu3NnoItUJ27dvZ9iwYTzwwAPcd999HDx4kL/97W84nU6ioqJ44YUXsNlsRhez\nVpsxYwYbN27E4XAwdOhQLr/8ctVBFcnNzWXUqFEcPXqUM2fOMGzYMDp06KDzb4C8vDxuueUWhg0b\nRnx8fI2sgxrbEt6wYQN79uxh6dKlTJkyhSlTphhdpDrBbrczadIk4uPji5a98sor3HPPPbz33nu0\nadOG5cuXG1jC2u+7775jx44dLF26lHnz5jF16lTVQRX64osv6NSpEwsXLmTWrFlMmzZN598gb775\nJg0bNgRq7udQjQ3h9evXk5iYCEC7du04efIk2dnZBpeq9rPZbMydO5fo6OiiZd9//z09e/YEoHv3\n7qxfv96o4tUJV199NbNnzwagQYMG5Obmqg6qUL9+/XjkkUcAOHjwIE2bNtX5N8CuXbvYuXMn3bp1\nA2ru51CNDeGsrCwiIiKKXkdGRpKZmWlgieoGq9VKSEhIsWW5ublFl30aN26seqhkFouF0NBQAJYv\nX85NN92kOjBASkoKTz31FGPGjNH5N8D06dMZNWpU0euaWgc1+p7wuTT6ZvWgeqg6a9euZfny5SxY\nsIBevXoVLVcdVI0lS5aQkZHB008/Xeyc6/xXvg8++IArr7ySVq1aeV1fk+qgxoZwdHQ0WVlZRa+P\nHDlCVFSUgSWqu0JDQ8nLyyMkJITDhw8Xu1QtlWPdunW89dZbzJs3j/DwcNVBFUpPT6dx48Y0b96c\nyy67DKfTSf369XX+q1BaWhp79+4lLS2NQ4cOYbPZauzvQI29HH3DDTeQmpoKwJYtW4iOjiYsLMzg\nUtVN119/fVFdfPrpp9x4440Gl6h2O336NDNmzGDOnDk0atQIUB1UpR9//JEFCxYAnttidrtd57+K\nzZo1i/fff59ly5Zx5513MmzYsBpbBzV6FqUXX3yRH3/8EZPJxPjx4+nQoYPRRar10tPTmT59Ovv3\n78dqtdK0aVNefPFFRo0axZkzZ4iJieH5558nKCjI6KLWWkuXLuXVV1+lbdu2RcumTZvG2LFjVQdV\nIC8vj7///e8cPHiQvLw8Hn/8cTp16sQzzzyj82+AV199lRYtWtC1a9caWQc1OoRFRERqshp7OVpE\nRKSmUwiLiIgYRCEsIiJiEIWwiIiIQRTCIiIiBlEIi4iIGEQhLCIiYhCFsIiIiEH+P/olP+vG2PUZ\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6434c26438>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZY7l0VXb-j7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Regular Training with a simple ConvNet \n",
        "#####  on the CIFAR10 dataset"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "sAEClUbg-j7S",
        "colab_type": "code",
        "outputId": "424d898b-2bf7-42f6-ad60-c8dde3bcf39b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1990
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Trains a simple convnet on the CIFAR10 dataset.\n",
        "with rmsprop optimizer\n",
        "'''\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "# input image dimensions\n",
        "img_height = 32\n",
        "img_width = 32\n",
        "channels = 3\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], channels, img_height, img_width)\n",
        "    x_test = x_test.reshape(x_test.shape[0], channels, img_height, img_width)\n",
        "    input_shape = (channels, img_height, img_width)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_height, img_width, channels)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_height, img_width, channels)\n",
        "    input_shape = (img_height, img_width, channels)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model_b = Sequential()\n",
        "model_b.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model_b.add(layers.BatchNormalization())\n",
        "model_b.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_b.add(layers.BatchNormalization())\n",
        "model_b.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_b.add(Dropout(0.25))\n",
        "model_b.add(Flatten())\n",
        "model_b.add(Dense(128, activation='relu'))\n",
        "model_b.add(layers.BatchNormalization())\n",
        "model_b.add(Dropout(0.5))\n",
        "model_b.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_b.compile(loss='categorical_crossentropy',\n",
        "              # replace by rmsprop for comparison\n",
        "              optimizer='rmsprop',\n",
        "              # Adding accuracy metrics \n",
        "              metrics=['accuracy'])\n",
        "callbacks_list = [\n",
        "    # Interrupts training when improvement stops\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Monitors the model’s validation accuracy\n",
        "        monitor='val_acc',\n",
        "        # Interrupts training when accuracy has stopped \n",
        "        # improving for more than one epoch (that is, two epochs)\n",
        "        patience=5,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Saves the current weights after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        # Path to the destination model file\n",
        "        filepath='model_b.h5',\n",
        "        # These two arguments mean you won’t overwrite the model file \n",
        "        # unless val_loss has improved, \n",
        "        monitor='val_loss',\n",
        "        # which allows you to keep the best model seen during training\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        # Monitors the model’s validation loss\n",
        "        monitor='val_loss',\n",
        "        # Divides the learning rate by 10 when triggered\n",
        "        factor=0.1,\n",
        "        # The callback is triggered after the validation loss \n",
        "        # has stopped improving for 1 epochs.\n",
        "        patience=3,\n",
        "        verbose=1\n",
        "    ) \n",
        "]\n",
        "\n",
        "model_b.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.4793 - acc: 0.5057 - val_loss: 1.2769 - val_acc: 0.5463\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.27690, saving model to model_b.h5\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.9980 - acc: 0.6520 - val_loss: 0.9947 - val_acc: 0.6450\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.27690 to 0.99474, saving model to model_b.h5\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.8459 - acc: 0.7068 - val_loss: 1.4733 - val_acc: 0.5679\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.99474\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.7521 - acc: 0.7387 - val_loss: 0.9695 - val_acc: 0.6720\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.99474 to 0.96953, saving model to model_b.h5\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6752 - acc: 0.7660 - val_loss: 1.0508 - val_acc: 0.6562\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.96953\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6172 - acc: 0.7873 - val_loss: 0.9907 - val_acc: 0.6721\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.96953\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5637 - acc: 0.8054 - val_loss: 1.0558 - val_acc: 0.6768\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.96953\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4325 - acc: 0.8540 - val_loss: 0.7704 - val_acc: 0.7445\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.96953 to 0.77045, saving model to model_b.h5\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4049 - acc: 0.8622 - val_loss: 0.7662 - val_acc: 0.7477\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.77045 to 0.76620, saving model to model_b.h5\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.3898 - acc: 0.8658 - val_loss: 0.7610 - val_acc: 0.7485\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.76620 to 0.76100, saving model to model_b.h5\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.3785 - acc: 0.8704 - val_loss: 0.7559 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.76100 to 0.75595, saving model to model_b.h5\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3681 - acc: 0.8745 - val_loss: 0.8011 - val_acc: 0.7495\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.75595\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.3561 - acc: 0.8793 - val_loss: 0.8246 - val_acc: 0.7469\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.75595\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3496 - acc: 0.8805 - val_loss: 0.7981 - val_acc: 0.7492\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.75595\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.3289 - acc: 0.8894 - val_loss: 0.7744 - val_acc: 0.7518\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.75595\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.3256 - acc: 0.8895 - val_loss: 0.7801 - val_acc: 0.7515\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.75595\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.3280 - acc: 0.8883 - val_loss: 0.7807 - val_acc: 0.7510\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.75595\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.3256 - acc: 0.8893 - val_loss: 0.7746 - val_acc: 0.7517\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.75595\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.3314 - acc: 0.8874 - val_loss: 0.7740 - val_acc: 0.7515\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.75595\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3278 - acc: 0.8883 - val_loss: 0.7754 - val_acc: 0.7513\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.75595\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6434b9d8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "6ZrzrV8VD01Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_b.load_weights('model_b.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUAJdc2z-j7c",
        "colab_type": "code",
        "outputId": "24c18084-ab30-44ba-9c28-93428453e5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "cell_type": "code",
      "source": [
        "score = model_b.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.7559461263656616\n",
            "Test accuracy: 0.7501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A3OdeUXNchoH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#下載模型的視覺化圖檔\n",
        "from keras.utils import plot_model\n",
        "plot_model(model_b, to_file='model_b.png')\n",
        "from google.colab import files\n",
        "files.download('model_b.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_aV-PjPR-j7p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The results are not very convincing. Depthwise separable convolution gives an accuracy of 55% that is inferior to the 70% of the simple ConvNet model. Probably that the model is not big /deep enough. "
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "lNoUROqR-j7q",
        "colab_type": "code",
        "outputId": "3f2b1116-ba73-49cc-9aaf-32e8b02f5e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1948
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Trains a simple convnet on the CIFAR10 dataset.\n",
        "with Adadelta optimizer\n",
        "'''\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "# input image dimensions\n",
        "img_height = 32\n",
        "img_width = 32\n",
        "channels = 3\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], channels, img_height, img_width)\n",
        "    x_test = x_test.reshape(x_test.shape[0], channels, img_height, img_width)\n",
        "    input_shape = (channels, img_height, img_width)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_height, img_width, channels)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_height, img_width, channels)\n",
        "    input_shape = (img_height, img_width, channels)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model_c = Sequential()\n",
        "model_c.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model_c.add(layers.BatchNormalization())\n",
        "model_c.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_c.add(layers.BatchNormalization())\n",
        "model_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_c.add(Dropout(0.25))\n",
        "model_c.add(Flatten())\n",
        "model_c.add(Dense(128, activation='relu'))\n",
        "model_c.add(layers.BatchNormalization())\n",
        "model_c.add(Dropout(0.5))\n",
        "model_c.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_c.compile(loss='categorical_crossentropy',\n",
        "              # The model_c is optimized with the Adadelta optimizer\n",
        "              optimizer='Adadelta',\n",
        "              # Adding accuracy metrics \n",
        "              metrics=['accuracy'])\n",
        "callbacks_list = [\n",
        "    # Interrupts training when improvement stops\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Monitors the model’s validation accuracy\n",
        "        monitor='val_acc',\n",
        "        # Interrupts training when accuracy has stopped \n",
        "        # improving for more than one epoch (that is, two epochs)\n",
        "        patience=5,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Saves the current weights after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        # Path to the destination model file\n",
        "        filepath='model_c.h5',\n",
        "        # These two arguments mean you won’t overwrite the model file \n",
        "        # unless val_loss has improved, \n",
        "        monitor='val_loss',\n",
        "        # which allows you to keep the best model seen during training\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        # Monitors the model’s validation loss\n",
        "        monitor='val_loss',\n",
        "        # Divides the learning rate by 10 when triggered\n",
        "        factor=0.1,\n",
        "        # The callback is triggered after the validation loss \n",
        "        # has stopped improving for 1 epochs.\n",
        "        patience=3,\n",
        "        verbose=1\n",
        "    ) \n",
        "]\n",
        "\n",
        "model_c.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 15s 295us/step - loss: 1.5036 - acc: 0.4956 - val_loss: 1.2605 - val_acc: 0.5521\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.26049, saving model to model_c.h5\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.9988 - acc: 0.6508 - val_loss: 0.9233 - val_acc: 0.6757\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.26049 to 0.92332, saving model to model_c.h5\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.8544 - acc: 0.7023 - val_loss: 0.8934 - val_acc: 0.6903\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.92332 to 0.89340, saving model to model_c.h5\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.7499 - acc: 0.7388 - val_loss: 0.8779 - val_acc: 0.6930\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.89340 to 0.87791, saving model to model_c.h5\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.6713 - acc: 0.7662 - val_loss: 0.9324 - val_acc: 0.6831\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.87791\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.6059 - acc: 0.7895 - val_loss: 0.9847 - val_acc: 0.6717\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.87791\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.5506 - acc: 0.8080 - val_loss: 0.8596 - val_acc: 0.7103\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.87791 to 0.85965, saving model to model_c.h5\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.5042 - acc: 0.8237 - val_loss: 0.8399 - val_acc: 0.7241\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.85965 to 0.83995, saving model to model_c.h5\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.4623 - acc: 0.8376 - val_loss: 0.8491 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.83995\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 0.4242 - acc: 0.8513 - val_loss: 0.8808 - val_acc: 0.7195\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.83995\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.3976 - acc: 0.8596 - val_loss: 1.0904 - val_acc: 0.6955\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.83995\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.1.\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.3076 - acc: 0.8930 - val_loss: 0.8179 - val_acc: 0.7450\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.83995 to 0.81793, saving model to model_c.h5\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.2845 - acc: 0.9035 - val_loss: 0.8147 - val_acc: 0.7480\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.81793 to 0.81472, saving model to model_c.h5\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.2758 - acc: 0.9054 - val_loss: 0.7933 - val_acc: 0.7489\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.81472 to 0.79331, saving model to model_c.h5\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.2688 - acc: 0.9072 - val_loss: 0.7994 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.79331\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.2580 - acc: 0.9125 - val_loss: 0.8217 - val_acc: 0.7497\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.79331\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.2510 - acc: 0.9136 - val_loss: 0.8004 - val_acc: 0.7472\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.79331\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 0.2395 - acc: 0.9195 - val_loss: 0.8134 - val_acc: 0.7489\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.79331\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.2400 - acc: 0.9189 - val_loss: 0.8123 - val_acc: 0.7489\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.79331\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.2418 - acc: 0.9163 - val_loss: 0.8130 - val_acc: 0.7484\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.79331\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f641ff92b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "AZRQJ7RVExAC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_c.load_weights('model_c.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "etC2i0qm-j7z",
        "colab_type": "code",
        "outputId": "55375c10-2def-4bcf-c94d-b053515a6c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "cell_type": "code",
      "source": [
        "score = model_c.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.7933071930885315\n",
            "Test accuracy: 0.7489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ayepsEfOdFk_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#下載模型的視覺化圖檔\n",
        "from keras.utils import plot_model\n",
        "plot_model(model_c, to_file='model_c.png')\n",
        "from google.colab import files\n",
        "files.download('model_c.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "idFiEnrV-j79",
        "colab_type": "code",
        "outputId": "2b270e3d-9a42-462f-c6ff-e824d1f81f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3019
        }
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple deep NN (MLP: Multi-Layer Perceptron) \n",
        "   on the CIFAR10 dataset.\n",
        "'''\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "# epochs = 12\n",
        "\n",
        "# the data, split between train and test sets\n",
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "# x_train = x_train.reshape(60000, 784)\n",
        "x_train = x_train.reshape(50000, 3072)\n",
        "# x_test = x_test.reshape(10000, 784)\n",
        "x_test = x_test.reshape(10000, 3072)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model_d = Sequential()\n",
        "# model_d.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model_d.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model_d.add(layers.BatchNormalization())\n",
        "model_d.add(Dropout(0.2))\n",
        "model_d.add(Dense(512, activation='relu'))\n",
        "model_d.add(layers.BatchNormalization())\n",
        "model_d.add(Dropout(0.2))\n",
        "model_d.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_d.summary()\n",
        "\n",
        "model_d.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "callbacks_list = [\n",
        "    # Interrupts training when improvement stops\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Monitors the model’s validation accuracy\n",
        "        monitor='val_acc',\n",
        "        # Interrupts training when accuracy has stopped \n",
        "        # improving for more than one epoch (that is, two epochs)\n",
        "        patience=5,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Saves the current weights after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        # Path to the destination model file\n",
        "        filepath='model_d.h5',\n",
        "        # These two arguments mean you won’t overwrite the model file \n",
        "        # unless val_loss has improved, \n",
        "        monitor='val_loss',\n",
        "        # which allows you to keep the best model seen during training\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        # Monitors the model’s validation loss\n",
        "        monitor='val_loss',\n",
        "        # Divides the learning rate by 10 when triggered\n",
        "        factor=0.1,\n",
        "        # The callback is triggered after the validation loss \n",
        "        # has stopped improving for 1 epochs.\n",
        "        patience=3,\n",
        "        verbose=1\n",
        "    ) \n",
        "]\n",
        "\n",
        "history = model_d.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,845,258\n",
            "Trainable params: 1,843,210\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 6s 130us/step - loss: 1.9234 - acc: 0.3471 - val_loss: 2.1850 - val_acc: 0.3013\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.18501, saving model to model_d.h5\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.6605 - acc: 0.4179 - val_loss: 1.8731 - val_acc: 0.3393\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.18501 to 1.87314, saving model to model_d.h5\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.5743 - acc: 0.4418 - val_loss: 1.6982 - val_acc: 0.3987\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.87314 to 1.69823, saving model to model_d.h5\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.5293 - acc: 0.4577 - val_loss: 1.7252 - val_acc: 0.3858\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.69823\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.4976 - acc: 0.4704 - val_loss: 2.3747 - val_acc: 0.2739\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.69823\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.4766 - acc: 0.4747 - val_loss: 1.6059 - val_acc: 0.4403\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.69823 to 1.60592, saving model to model_d.h5\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.4493 - acc: 0.4875 - val_loss: 1.5147 - val_acc: 0.4629\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.60592 to 1.51466, saving model to model_d.h5\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 5s 105us/step - loss: 1.4325 - acc: 0.4906 - val_loss: 1.5417 - val_acc: 0.4454\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.51466\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.4175 - acc: 0.4955 - val_loss: 1.5175 - val_acc: 0.4683\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.51466\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 5s 106us/step - loss: 1.4088 - acc: 0.4995 - val_loss: 1.5493 - val_acc: 0.4505\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.51466\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 5s 106us/step - loss: 1.3382 - acc: 0.5262 - val_loss: 1.3138 - val_acc: 0.5369\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.51466 to 1.31377, saving model to model_d.h5\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.3193 - acc: 0.5320 - val_loss: 1.3080 - val_acc: 0.5397\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.31377 to 1.30805, saving model to model_d.h5\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 5s 103us/step - loss: 1.3091 - acc: 0.5379 - val_loss: 1.3018 - val_acc: 0.5442\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.30805 to 1.30182, saving model to model_d.h5\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.3029 - acc: 0.5384 - val_loss: 1.3077 - val_acc: 0.5376\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.30182\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 5s 103us/step - loss: 1.3002 - acc: 0.5396 - val_loss: 1.3024 - val_acc: 0.5435\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.30182\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.2930 - acc: 0.5409 - val_loss: 1.2989 - val_acc: 0.5394\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.30182 to 1.29890, saving model to model_d.h5\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.2851 - acc: 0.5428 - val_loss: 1.3028 - val_acc: 0.5388\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.29890\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.2870 - acc: 0.5452 - val_loss: 1.2897 - val_acc: 0.5451\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.29890 to 1.28973, saving model to model_d.h5\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.2807 - acc: 0.5451 - val_loss: 1.2937 - val_acc: 0.5445\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.28973\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.2795 - acc: 0.5456 - val_loss: 1.2891 - val_acc: 0.5424\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.28973 to 1.28909, saving model to model_d.h5\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 5s 103us/step - loss: 1.2757 - acc: 0.5471 - val_loss: 1.2863 - val_acc: 0.5471\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.28909 to 1.28630, saving model to model_d.h5\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 5s 105us/step - loss: 1.2672 - acc: 0.5533 - val_loss: 1.2858 - val_acc: 0.5479\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.28630 to 1.28582, saving model to model_d.h5\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 5s 103us/step - loss: 1.2708 - acc: 0.5469 - val_loss: 1.2854 - val_acc: 0.5481\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.28582 to 1.28542, saving model to model_d.h5\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.2676 - acc: 0.5519 - val_loss: 1.2858 - val_acc: 0.5434\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.28542\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 5s 103us/step - loss: 1.2610 - acc: 0.5530 - val_loss: 1.2882 - val_acc: 0.5433\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.28542\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 5s 103us/step - loss: 1.2613 - acc: 0.5542 - val_loss: 1.2897 - val_acc: 0.5443\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.28542\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 5s 103us/step - loss: 1.2499 - acc: 0.5591 - val_loss: 1.2777 - val_acc: 0.5463\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.28542 to 1.27766, saving model to model_d.h5\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 5s 104us/step - loss: 1.2469 - acc: 0.5591 - val_loss: 1.2756 - val_acc: 0.5476\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.27766 to 1.27556, saving model to model_d.h5\n",
            "Epoch 00028: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6v5EgVK_G5cP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_d.load_weights('model_d.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0PU0Xcgy-j8E",
        "colab_type": "code",
        "outputId": "9ad4b6b2-ce90-4519-f69f-2d8978370a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "cell_type": "code",
      "source": [
        "score = model_d.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.2755645107269287\n",
            "Test accuracy: 0.5476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-b9Azd6cdWsG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#下載模型的視覺化圖檔\n",
        "from keras.utils import plot_model\n",
        "plot_model(model_d, to_file='model_d.png')\n",
        "from google.colab import files\n",
        "files.download('model_d.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qhDKhQIC-j8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.3.2. Hyperparameter optimization \n",
        "\n",
        "When building a deep-learning model, you have to make many seemingly arbitrary decisions: How many layers should you stack? How many units or filters should go in each layer? Should you use `relu` as activation, or a different function? Should you use `BatchNormalization` after a given layer? How much dropout should you use? And so on. These architecture-level parameters are called <i>hyperparameters</i> to distinguish them from the parameters of a model, which are trained via backpropagation. \n",
        "\n",
        "In practice, experienced machine-learning engineers and researchers build intuition over time as to what works and what doesn’t when it comes to these choices—they develop hyperparameter-tuning skills. But there are no formal rules. If you want to get to the very limit of what can be achieved on a given task, you can’t be content with arbitrary choices made by a fallible human. Your initial decisions are almost always suboptimal, even if you have good intuition. You can refine your choices by tweaking them by hand and retraining the model repeatedly—that’s what machine-learning engineers and researchers spend most of their time doing. But it shouldn’t be your job as a human to fiddle with hyperparameters all day—that is better left to a machine. \n",
        "\n",
        "Thus you need to explore the space of possible decisions automatically, systematically, in a principled way. You need to search the architecture space and find the best-performing ones empirically. That’s what the field of automatic hyperparameter optimization is about: it’s an entire field of research, and an important one.\n",
        "\n",
        "The process of optimizing hyperparameters typically looks like this: \n",
        "\n",
        "* Choose a set of hyperparameters (automatically).\n",
        "* Build the corresponding model.\n",
        "* Fit it to your training data, and measure the final performance on the validation data. \n",
        "* Choose the next set of hyperparameters to try (automatically). \n",
        "* Repeat. \n",
        "* Eventually, measure performance on your test data. \n",
        "\n",
        "The key to this process is the algorithm that uses this history of validation performance, given various sets of hyperparameters, to choose the next set of hyperparameters to evaluate. Many different techniques are possible: Bayesian optimization (https://en.wikipedia.org/wiki/Bayesian_optimization), genetic algorithms (https://en.wikipedia.org/wiki/Genetic_algorithm), simple random search (https://en.wikipedia.org/wiki/Random_search), and so on.\n",
        "\n",
        "The key to this process is the algorithm that uses this history of validation performance, given various sets of hyperparameters, to choose the next set of hyperparameters to evaluate. Many different techniques are possible: Bayesian optimization, genetic algorithms, simple random search, and so on. \n",
        "\n",
        "Training the weights of a model is relatively easy: you compute a loss function on a mini-batch of data and then use the Backpropagation algorithm to move the weights in the right direction. Updating hyperparameters, on the other hand, is extremely challenging. Consider the following: \n",
        "\n",
        "* Computing the feedback signal (does this set of hyperparameters lead to a high-performing model on this task?) can be extremely expensive: it requires creating and training a new model from scratch on your dataset. \n",
        "* The hyperparameter space is typically made of discrete decisions and thus isn’t continuous or differentiable. Hence, you typically can’t do gradient descent in hyperparameter space. Instead, you must rely on gradient-free optimization techniques, which naturally are far less efficient than gradient descent.\n",
        "\n",
        "Because these challenges are difficult and the field is still young, we currently only have access to very limited tools to optimize models. Often, it turns out that random search (choosing hyperparameters to evaluate at random, repeatedly) is the best solution, despite being the most naive one. But one tool I have found reliably better than random search is Hyperopt (https://github.com/hyperopt/hyperopt), a Python library for hyperparameter optimization that internally uses trees of Parzen estimators to predict sets of hyperparameters that are likely to work well. Another library called Hyperas (https://github.com/maxpumperla/hyperas) integrates Hyperopt for use with Keras models. Do check it out.\n",
        "\n",
        "** Note ** \n",
        "> One important issue to keep in mind when doing automatic hyperparameter optimization at scale is validation-set overfitting. Because you’re updating hyperparameters based on a signal that is computed using your validation data, you’re effectively training them on the validation data, and thus they will quickly overfit to the validation data. Always keep this in mind.\n",
        "\n",
        "Overall, hyperparameter optimization is a powerful technique that is an absolute requirement to get to state-of-the-art models on any task or to win machine-learning competitions. Think about it: once upon a time, people handcrafted the features that went into shallow machine-learning models. That was very much suboptimal. Now, deep learning automates the task of hierarchical feature engineering—features are learned using a feedback signal, not hand-tuned, and that’s the way it should be. In the same way, you shouldn’t handcraft your model architectures; you should optimize them in a principled way. At the time of writing, the field of automatic hyperparameter optimization is very young and immature, as deep learning was some years ago, but I expect it to boom in the next few years."
      ]
    },
    {
      "metadata": {
        "id": "EJzVm2NB-j8e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.3.3. Model ensembling \n",
        "Another powerful technique for obtaining the best possible results on a task is model ensembling. Ensembling consists of pooling together the predictions of a set of different models, to produce better predictions. If you look at machine-learning competitions, in particular on Kaggle, you’ll see that the winners use very large ensembles of models that inevitably beat any single model, no matter how good. \n",
        "\n",
        "Ensembling relies on the assumption that different good models trained independently are likely to be good for different reasons: each model looks at slightly different aspects of the data to make its predictions, getting part of the “truth” but not all of it. You may be familiar with the ancient parable of the blind men and the elephant: a group of blind men come across an elephant for the first time and try to understand what the elephant is by touching it. Each man touches a different part of the elephant’s body—just one part, such as the trunk or a leg. Then the men describe to each other what an elephant is: “It’s like a snake,” “Like a pillar or a tree,” and so on. The blind men are essentially machine-learning models trying to understand the manifold of the training data, each from its own perspective, using its own assumptions (provided by the unique architecture of the model and the unique random weight initialization). Each of them gets part of the truth of the data, but not the whole truth. By pooling their perspectives together, you can get a far more accurate description of the data. The elephant is a combination of parts: not any single blind man gets it quite right, but, interviewed together, they can tell a fairly accurate story. \n",
        "\n",
        "Let’s use classification as an example. The easiest way to pool the predictions of a set of classifiers (to ensemble the classifiers) is to average their predictions at inference time:"
      ]
    },
    {
      "metadata": {
        "id": "bn7cNVrL-j8g",
        "colab_type": "code",
        "outputId": "de9b65cf-7160-4ddb-dd9c-092577c3d95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3072)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "IkVekl8E-j8r",
        "colab_type": "code",
        "outputId": "e0b2f933-423b-42d4-dd1f-c108b07ed64a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "x_val = x_test.reshape(10000, 32, 32, 3)\n",
        "# Use four different models to compute initial predictions.\n",
        "preds_a = model_a.predict(x_val)\n",
        "preds_b = model_b.predict(x_val)\n",
        "preds_c = model_c.predict(x_val)\n",
        "preds_d = model_d.predict(x_test)\n",
        "\n",
        "# This new prediction array should be more accurate than any of the initial ones.\n",
        "final_preds = 0.25 * (preds_a + preds_b + preds_c + preds_d)\n",
        "\n",
        "import numpy as np\n",
        "final_preds_one_hot = np.zeros_like(final_preds)\n",
        "final_preds_one_hot[np.arange(len(final_preds)), final_preds.argmax(1)] = 1\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, final_preds_one_hot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "bF1cRgOu-j87",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This will work only if the classifiers are more or less equally good. If one of them is significantly worse than the others, the final predictions may not be as good as the best classifier of the group. A smarter way to ensemble classifiers is to do a weighted average, where the weights are learned on the validation data—typically, the better classifiers are given a higher weight, and the worse classifiers are given a lower weight. To search for a good set of ensembling weights, you can use random search or a simple optimization algorithm such as Nelder-Mead.\n",
        "\n",
        "With a homemade one_hot_encoder and accuracy_score from Scikit Learn:"
      ]
    },
    {
      "metadata": {
        "id": "ej3jM8hPIMNn",
        "colab_type": "code",
        "outputId": "219a86a7-82da-4e35-9d06-8be3f8db7a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "final_preds = 0.40 * preds_a + 0.35 * preds_b + 0.15 * preds_c + 0.1 * preds_d \n",
        "final_preds_one_hot = np.zeros_like(final_preds)\n",
        "final_preds_one_hot[np.arange(len(final_preds)), final_preds.argmax(1)] = 1\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, final_preds_one_hot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "r7clzEGl-j9C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With a Keras one_hot encoder and accuracy_score from Scikit Learn:"
      ]
    },
    {
      "metadata": {
        "id": "-HOUgqei-j9D",
        "colab_type": "code",
        "outputId": "6ac37831-bd44-4c38-b249-912e1a63d21b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "final_preds_one_hot = K.one_hot(K.argmax(final_preds,axis=1),10)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,tf.Session().run(final_preds_one_hot))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "Ig1Cda2PKK3Z",
        "colab_type": "code",
        "outputId": "00a7fa5e-0964-468f-95be-11455c937381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "final_preds_one_hot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'one_hot:0' shape=(10000, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "AmQtFYFrKU1m",
        "colab_type": "code",
        "outputId": "e2fc0039-7a34-41cb-da24-bfaedc10973e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "final_preds.argmax(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 8, ..., 5, 1, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "YNtm-UciKnCw",
        "colab_type": "code",
        "outputId": "692dc233-1202-44a8-ed89-d1d888393ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "np.arange(len(final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 9997, 9998, 9999])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "h2qfk8Yz-j9I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are many possible variants: you can do an average of an exponential of the predictions, for instance. In general, a simple weighted average with weights optimized on the validation data provides a very strong baseline. \n",
        "\n",
        "The key to making ensembling work is the <i>diversity</i> of the set of classifiers. Diversity is strength. If your models are <i>biased in different ways</i>, the biases will cancel each other out, and the ensemble will be more robust and more accurate. \n",
        "\n",
        "For this reason, you should ensemble models that are <i>as good as possible</i> while being as different as possible. This typically means using very different architectures or even different brands of machine-learning approaches. One thing that is largely not worth doing is ensembling the same network trained several times independently, from different random initializations. If the only difference between your models is their random initialization and the order in which they were exposed to the training data, then your ensemble will be low-diversity and will provide only a tiny improvement over any single model. The point of ensembling. It’s not so much about how good your best model is; it’s about the diversity of your set of candidate models. \n",
        "\n",
        "In recent times, one style of basic ensemble that has been very successful in practice is the wide and deep category of models, blending deep learning with shallow learning. Such models consist of jointly training a deep neural network with a large linear model. The joint training of a family of diverse models is yet another option to achieve model ensembling. "
      ]
    },
    {
      "metadata": {
        "id": "Sfix8Yi04rpA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!py3clean ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ldwCEeUrF8cy",
        "colab_type": "code",
        "outputId": "5167d6f9-6158-4763-a80c-9d487d967a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "KKbh0t4WGhlY",
        "colab_type": "code",
        "outputId": "a2d8cc2c-53dd-44f1-dfa5-bb0d2a22a08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "3sN9bRRpGm7L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}